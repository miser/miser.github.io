{"pages":[],"posts":[{"title":"Set A Flag","text":"Practice speaking and listening, pass the BEC exam.","link":"/2019/06/19/bec/"},{"title":"码农与画家","text":"又想起了那本《黑客与画家》最近总是想起这个书名，多年前在图灵社区购买的电子本，对于当时的自己来说感觉有些不适用，以至于内容忘记的差不多了，仅仅是书名让人感觉非常酷。写该文的时候又去翻阅了下，感觉有些东西还是很有趣的，有时间应该重读下。 过往的自己，手上大多是工具书，应用相关的，希望通过书中的介绍知道一个个技术的细节，感觉每看一页都是收获满满，对于《黑客与画家》这样非直观的技术呈现显得不感兴趣。 现在的自己，愿意通过源码去寻找技术细节（也是拜这些年 github 等社区带来的便利），更多是希望知道那些技术大师如何思考、如何设计程序、如何架构系统，需要更多其它的信息来构建自己的认知体系。为什么这样做比这是怎么做显得更加重要，为什么是因，怎么是果。 最近在给团队里年轻同事做培训或 Code Review 的时候也是感触良多，总是想起过去的自己，脑子中又闪现出了，码农与程序猿。 业务总是无穷尽这是一件好事情，正因为如此我们才得以有工作，有收入养活自己和家人。 过去的自己经常觉得上面分配下来的任务能合理规划时间，在预定的时间内完成是件非常了不起的事情，显示出自己的诚实有信，当然这条是永远不会过时的职场优点，也会让别人愿意和你合作。不过，当我们放下脚步，去细细询问一些细节，比如究竟是什么让你如此高效的话，一些坏味道会浮现上来，比如： 新的业务需求，新的 if-else 判断 相似的功能点，重复的 Ctrl + C 和 Ctrl + V 不断横向扩展的方法入参…… 野蛮生长的代码往后或许会给别人，让 TA 们继续野蛮，而自己可能也习惯了简单粗暴的方式，在业务中“乐此不疲”，一年到头除了业务知识的长进和一些细枝末节的技术知识（比如，“远古时期”如何兼容各 IE 版本的样式，现在好了微软要结束对 IE 的支持了），对那些涌现的新技术，再也学不动了。似乎转产品、转管理是唯一的出路，因为之前创过业，做产品考虑的问题不比技术少，头发也是一把把掉；现在做点管理，同样要考虑很多，对上要规划和争取、对下要安抚和培养，反而做技术乐得自在，无非就是多学习，最后都是自己的财富。 大多是平庸的除了少数悟性高、脚踏实地、心智成熟的人之外，大部分都是平庸的。专业能力的提升需要悟性，把知识转化为产品需要脚踏实地的去做，团队协作、把东西做大做强需要心智成熟。我没有把天才列在上述 3 大特点之内，历史的长河中，自命不凡的天才都死的太早，而且大多自己作死。我自己也有时懊恼为什么之前要去和朋友创业，如果安心工作，也许又是一番风景了。应该和自己的平庸做妥协，这样也会顺理成章的接受他人的平庸，相互善待，摆正好心态，不管结果如何至少过程会让自己愉悦点，不能总说啊 Q 精神总是一无是处的。 油画总是涂了一层又一层一个公司真正赚钱的业务线就那么几条，能做架构的也就那么些人，大部分是平庸无聊又被无尽业务业务淹没的码农，似乎能一眼望到老。 陈旧的老系统、他人的神奇代码，你不得不必须花大量的精力去和它们搏斗，日复一日的耗尽你一切，一不小心就被吞噬，这些远没有新需求、新系统来的香，你可以安心的饲养自己的怪兽。过去的自己也极其喜欢这为所欲为的状态，但是我并没有好的悟性，无法凭空在纯净的土壤中生出“花”来，不断做新的，学习新的东西只是徒增了一些快乐，成长总是伴随着痛苦的迭代，和过去的自己持续搏斗，你会 明白为什么会要做这样或那样的修改，去满足时而复杂时而简单的需求 为了能早点下班，只能思考如何偷懒，有点被多方胁迫的感觉，尝试一些设计，去满足不同业务变化，各类设计模式和编程模型会出现在项目的各个角落 好的继续保持，坏的用别的替换或组合着用 代码也时而膨胀，时而精简 系统也经常神经质般的出现一些纰漏 又是为了早点下班，把单元测试、集成测试等等引入进来，尽可能束缚中手上的怪兽 时间长了，你会发现 系统在设计模式和编程模型的加持下，变得有条不紊 需求的变换，无非就是对一些模块更迭，不同的模块组合又能实现新的需求 想想各类 UI 组件库、插件机制、中间件机制等，无非就是处理了一些场景（其实也是业务）的抽象需求 而我们自己将业务中的点点滴滴汇集起来，不也就是属于自己的一套编程经验了吗，并没有那么多的不同 当你在感叹第三方类库彬彬有礼的时候，是否也察觉自己也把手上的系统变得礼貌了许多呢 “简历上如何才能体现亮点”| 这是在做培训的时候，一个实习生问的。 作为一个快要毕业的研究生来说，比起我这个低学历的“老年人”来说已经是极大的亮点了。平时也给她做了不少培训，影印了不少资料，但是真的能运用到工作中的还是有限的，倒不是她不努力，只是经验尚浅，不知道该如何运用，还需要更多重复在一张纸上画画，这不是教出来而是练出来，并自己总结悟出来的。那些流行度极广的框架或类库都是把“垃圾”工作有效的整理和隐藏起来，你只需要“精致”的去运用上层就好。把垃圾转为精致不就是亮点吗？ 想要建造罗马城，应该学会砌砖，整个过程需要数年时间。 迭代需要时间，而技术工作的寿命又显得那么短暂，外面的培训机构各类的花式广告标语又在制造一场场焦虑，身边的朋友同学工资早已翻倍，而自己依旧平庸。我也想不出什么好的办法，唯一能做的是持续的画画，不断的画画，一层又一层，把会的分享出去，把困惑和别人探讨，既然平庸更该为下一次机会做好准备。 码农与画家我想所有的工作都是需要日夜重复，在平庸中找寻突破的，无论是码农还是画家，很多时候是孤独的在和手上的作品搏斗。 上面的东西，最近总是在脑子里出现，最后还是决定写下来。本想写的细点，突出一些重点，但自己并没有什么真本事是列举，大道理都明白，就像很多成功学的书一样，废话多于实操。 对于刚毕业或工作没几年的朋友来说或许是不适用的。而对于像我这样的“老年人”来说反而有闲暇时间去画画了。","link":"/2020/08/16/coder-painter/"},{"title":"简单梳理Node.js创建子进程的方法（上）","text":"Node.js 创建子进程的方法常用的有如下几种： child_process exec: 衍生一个 shell 然后在该 shell 中执行 command，并缓冲任何产生的输出，最大缓存 1024*1024 个字节。 execFile: 函数类似exec，但默认情况下不会衍生 shell。 相反，指定的可执行文件file 会作为新进程直接地衍生，使其比exec 稍微更高效。和exec一样，它也有最大 1024*1204 个字节的显示缓存。 fork: 是 spawn的一个特例，专门用于衍生新的 Node.js 进程。 与spawn一样返回ChildProcess对象。 返回的ChildProcess将会内置一个额外的通信通道，允许消息在父进程和子进程之间来回传递。 spawn: 上诉的几个方法其实都是通过 spawn 实现的。 cluster fork: 衍生出一个新的工作进程，这只能通过主进程调用。 翻翻源码看看他们怎么实现的源码版本和之前的libuv &amp; Node.js EventLoop （一）一样 123456789101112131415// libuv#define UV_VERSION_MAJOR 1#define UV_VERSION_MINOR 33#define UV_VERSION_PATCH 1// V8#define V8_MAJOR_VERSION 7#define V8_MINOR_VERSION 8#define V8_BUILD_NUMBER 279#define V8_PATCH_LEVEL 17// Node.js#define NODE_MAJOR_VERSION 14#define NODE_MINOR_VERSION 0#define NODE_PATCH_VERSION 0 child_process源码位置 12345Node - lib - internal - child_process.js - child_process.js; 在lib/child_process.js文件中，定义了exec、execFile、fork和spawn等方法，它们最后都会调用在lib/internal/child_process.js文件中的spawn方法。 exec 123456789101112131415161718192021// lib/child_process.jsfunction exec(command, options, callback) &#123; const opts = normalizeExecArgs(command, options, callback); return module.exports.execFile(opts.file, opts.options, opts.callback);&#125;function normalizeExecArgs(command, options, callback) &#123; if (typeof options === \"function\") &#123; callback = options; options = undefined; &#125; // Make a shallow copy so we don't clobber the user's options object. options = &#123; ...options &#125;; options.shell = typeof options.shell === \"string\" ? options.shell : true; return &#123; file: command, options: options, callback: callback, &#125;;&#125; 从上面发现 exec 其实就是封装了参数，主要是开启shell参数，然后调用 execFile 方法。 execFile 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173// lib/child_process.jsfunction execFile(file /* , args, options, callback */) &#123; let args = []; let callback; let options; // ... options = &#123; encoding: \"utf8\", timeout: 0, maxBuffer: MAX_BUFFER, killSignal: \"SIGTERM\", cwd: null, env: null, shell: false, // execFile 默认是不开启shell ...options, &#125;; // 通过spawn方法创建子进程 const child = spawn(file, args, &#123; cwd: options.cwd, env: options.env, gid: options.gid, uid: options.uid, shell: options.shell, windowsHide: !!options.windowsHide, windowsVerbatimArguments: !!options.windowsVerbatimArguments, &#125;); var encoding; const _stdout = []; // 输出的内容 const _stderr = []; // 出错的内容 // ... var stdoutLen = 0; // 输出内容的长度 var stderrLen = 0; // 出错内容的长度 var killed = false; // 是否已经被杀死 var exited = false; // 是否已经退出 var timeoutId; // 是否有定时器 var ex = null; // 出错的上下文对象 var cmd = file; // 命令或文件 // 退出回调方法 function exithandler(code, signal) &#123; if (exited) return; exited = true; if (timeoutId) &#123; clearTimeout(timeoutId); timeoutId = null; &#125; if (!callback) return; // merge chunks var stdout; var stderr; if (encoding || (child.stdout &amp;&amp; child.stdout.readableEncoding)) &#123; stdout = _stdout.join(\"\"); &#125; else &#123; stdout = Buffer.concat(_stdout); // 如果不传入 encoding 参数，默认是Buffer拼接输出 &#125; if (encoding || (child.stderr &amp;&amp; child.stderr.readableEncoding)) &#123; stderr = _stderr.join(\"\"); &#125; else &#123; stderr = Buffer.concat(_stderr); // 如果不传入 encoding 参数，默认是Buffer拼接输出 &#125; if (!ex &amp;&amp; code === 0 &amp;&amp; signal === null) &#123; callback(null, stdout, stderr); // 没有错误，执行回调 return; &#125; if (args.length !== 0) cmd += ` $&#123;args.join(\" \")&#125;`; if (!ex) &#123; // eslint-disable-next-line no-restricted-syntax ex = new Error(\"Command failed: \" + cmd + \"\\n\" + stderr); ex.killed = child.killed || killed; ex.code = code &lt; 0 ? getSystemErrorName(code) : code; ex.signal = signal; &#125; ex.cmd = cmd; callback(ex, stdout, stderr); // 有错误，执行回调 &#125; function errorhandler(e) &#123; ex = e; // child.stdout 和 child.stderr 都销毁 if (child.stdout) child.stdout.destroy(); if (child.stderr) child.stderr.destroy(); exithandler(); &#125; function kill() &#123; if (child.stdout) child.stdout.destroy(); if (child.stderr) child.stderr.destroy(); killed = true; try &#123; child.kill(options.killSignal); &#125; catch (e) &#123; ex = e; exithandler(); &#125; &#125; // 如果定义了子进程的超时时间，就定时销毁它 if (options.timeout &gt; 0) &#123; timeoutId = setTimeout(function delayedKill() &#123; kill(); timeoutId = null; &#125;, options.timeout); &#125; if (child.stdout) &#123; if (encoding) child.stdout.setEncoding(encoding); child.stdout.on(\"data\", function onChildStdout(chunk) &#123; const encoding = child.stdout.readableEncoding; const length = encoding ? Buffer.byteLength(chunk, encoding) : chunk.length; stdoutLen += length; // 不断累加输出的长度 if (stdoutLen &gt; options.maxBuffer) &#123; // 超过的话就报错 const truncatedLen = options.maxBuffer - (stdoutLen - length); _stdout.push(chunk.slice(0, truncatedLen)); ex = new ERR_CHILD_PROCESS_STDIO_MAXBUFFER(\"stdout\"); kill(); &#125; else &#123; _stdout.push(chunk); // 不断累积chunk &#125; &#125;); &#125; // 整体逻辑和上面的child.stdout基本一致 if (child.stderr) &#123; if (encoding) child.stderr.setEncoding(encoding); child.stderr.on(\"data\", function onChildStderr(chunk) &#123; const encoding = child.stderr.readableEncoding; const length = encoding ? Buffer.byteLength(chunk, encoding) : chunk.length; stderrLen += length; if (stderrLen &gt; options.maxBuffer) &#123; const truncatedLen = options.maxBuffer - (stderrLen - length); _stderr.push(chunk.slice(0, truncatedLen)); ex = new ERR_CHILD_PROCESS_STDIO_MAXBUFFER(\"stderr\"); kill(); &#125; else &#123; _stderr.push(chunk); &#125; &#125;); &#125; child.addListener(\"close\", exithandler); child.addListener(\"error\", errorhandler); return child;&#125; exec和execFile最大的一个区别就是参数shell默认是否开启，其它基本都是相同的。另外，它们对输出的内容有大小限制是在child.stderr.on(&#39;data&#39;)和child.stdout.on(&#39;data&#39;)获取数据时候被限制。 如果不做类似的规定，_stderr和_stdout无限被输出，那么内存会不断的膨胀导致性能问题，甚至程序奔溃。（这是我猜的原因） 另外说到底，最后还是对spawn方法的封装了调用。 fork 12345678910111213141516171819202122232425262728// lib/child_process.jsfunction fork(modulePath /* , args, options */) &#123; // Get options and args arguments. var execArgv; var options = &#123;&#125;; var args = []; // ... // fork方法的stdio参数，必须带有一个ipc参数 if (typeof options.stdio === \"string\") &#123; options.stdio = stdioStringToArray(options.stdio, \"ipc\"); &#125; else if (!Array.isArray(options.stdio)) &#123; // Use a separate fd=3 for the IPC channel. Inherit stdin, stdout, // and stderr from the parent if silent isn't set. options.stdio = stdioStringToArray( options.silent ? \"pipe\" : \"inherit\", \"ipc\" ); &#125; else if (!options.stdio.includes(\"ipc\")) &#123; throw new ERR_CHILD_PROCESS_IPC_REQUIRED(\"options.stdio\"); &#125; options.execPath = options.execPath || process.execPath; // 默认用父进程的Node执行文件 options.shell = false; // 不开启 shell return spawn(options.execPath, args, options);&#125; 从上面代码有个非常引人注意就是 12~22 行，fork 方法的 stdio 参数，必须带有一个 ipc 参数，这个ipc的作用将在后续深入挖掘后介绍。最后也是调用spawn创建子进程。 spawn 12345678910// lib/child_process.jsfunction spawn(file, args, options) &#123; const child = new ChildProcess(); options = normalizeSpawnArguments(file, args, options); debug(\"spawn\", options); child.spawn(options); return child;&#125; lib/child_process.js里的 spawn 方法就简单的将传入的参数做整理，然后直接调用 ChildProcess 实例对象的 spawn。 ChildProcess 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122// `lib/internal/child_process.js`function ChildProcess() &#123; EventEmitter.call(this); // ... this._handle = new Process(); // new 出一个 ProcessWrap 对象 （ process_wrap.cc）&#125;ChildProcess.prototype.spawn = function (options) &#123; let i = 0; // 默认使用 pipe let stdio = options.stdio || \"pipe\"; // 重置stdio变量，这个是个很重要的方法，后续将继续介绍 stdio = getValidStdio(stdio, false); const ipc = stdio.ipc; const ipcFd = stdio.ipcFd; stdio = options.stdio = stdio.stdio; // ... // 调用ProcessWrap对应的spawn去创建新进程 const err = this._handle.spawn(options); // 如果err存在，就会有相关代码处理创建子进程出错的场景 // ... this.pid = this._handle.pid; for (i = 0; i &lt; stdio.length; i++) &#123; const stream = stdio[i]; // ... if (stream.handle) &#123; // When i === 0 - we're dealing with stdin // (which is the only one writable pipe). // 创建 socket stream.socket = createSocket( this.pid !== 0 ? stream.handle : null, i &gt; 0 ); if (i &gt; 0 &amp;&amp; this.pid !== 0) &#123; this._closesNeeded++; stream.socket.on(\"close\", () =&gt; &#123; maybeClose(this); &#125;); &#125; &#125; &#125; this.stdin = stdio.length &gt;= 1 &amp;&amp; stdio[0].socket !== undefined ? stdio[0].socket : null; this.stdout = stdio.length &gt;= 2 &amp;&amp; stdio[1].socket !== undefined ? stdio[1].socket : null; this.stderr = stdio.length &gt;= 3 &amp;&amp; stdio[2].socket !== undefined ? stdio[2].socket : null; this.stdio = []; for (i = 0; i &lt; stdio.length; i++) this.stdio.push(stdio[i].socket === undefined ? null : stdio[i].socket); // Add .send() method and start listening for IPC data // setupChannel 方法很长，主要就是实现了数据的发送和接受 if (ipc !== undefined) setupChannel(this, ipc); return err;&#125;;function stdioStringToArray(stdio, channel) &#123; // 主要将stdio参数格式化为[xxx,xxx,xxx]形式的数组 // 如果有channel，[xxx,xxx,xxx,channel]&#125;function getValidStdio(stdio, sync) &#123; var ipc; var ipcFd; stdio = stdio.reduce((acc, stdio, i) =&gt; &#123; function cleanup() &#123; for (var i = 0; i &lt; acc.length; i++) &#123; if ((acc[i].type === \"pipe\" || acc[i].type === \"ipc\") &amp;&amp; acc[i].handle) acc[i].handle.close(); &#125; &#125; if (stdio === \"ignore\") &#123; acc.push(&#123; type: \"ignore\" &#125;); // 子进程的输出不需要在控制台显示 &#125; else if (stdio === \"pipe\" || (typeof stdio === \"number\" &amp;&amp; stdio &lt; 0)) &#123; var a = &#123; type: \"pipe\", readable: i === 0, // 0是stdin，需要读 writable: i !== 0, // 1是stdout，2是stderr 需要写 &#125;; // spawn 调用的时候，sync为false，为stdin、stdout、stderr创建一个SOCKET类型Pipe if (!sync) a.handle = new Pipe(PipeConstants.SOCKET); acc.push(a); &#125; else if (stdio === \"ipc\") &#123; // 创建一个IPC类型Pipe ipc = new Pipe(PipeConstants.IPC); ipcFd = i; // ipc位置 acc.push(&#123; type: \"pipe\", handle: ipc, ipc: true, &#125;); &#125; else if (stdio === \"inherit\") &#123; acc.push(&#123; type: \"inherit\", fd: i, &#125;); &#125; // ...还有很多代码，不在讨论范围 return acc; &#125;, []); return &#123; stdio, ipc, ipcFd &#125;;&#125; ChildProcess并不能直接创建新的进程，需要底层 V8 的帮助，在构造函数里面直接 new ProcessWrap 赋给了 this._handle。 ChildProcess.prototype.spawn开始主要处理主要的stdio参数，明确父子进程通过哪些方式来获取数据信息，官方文档给出了一些示例，如果不清楚可以多做点实验。如果是pipe或者是ipc都会实例化一个 Pipe 对象，只是参数类型不同。 123456789101112131415161718192021222324252627282930// pipe_wrap.ccvoid PipeWrap::New(const FunctionCallbackInfo&lt;Value&gt;&amp; args) &#123; switch (type) &#123; case SOCKET: provider = PROVIDER_PIPEWRAP; ipc = false; break; case IPC: provider = PROVIDER_PIPEWRAP; ipc = true; break; &#125; new PipeWrap(env, args.This(), provider, ipc);&#125;PipeWrap::PipeWrap(Environment* env, Local&lt;Object&gt; object, ProviderType provider, bool ipc) : ConnectionWrap(env, object, provider) &#123; int r = uv_pipe_init(env-&gt;event_loop(), &amp;handle_, ipc);&#125;// deps/uv/src/unix/pipe.cint uv_pipe_init(uv_loop_t* loop, uv_pipe_t* handle, int ipc) &#123; uv__stream_init(loop, (uv_stream_t*)handle, UV_NAMED_PIPE); handle-&gt;shutdown_req = NULL; handle-&gt;connect_req = NULL; handle-&gt;pipe_fname = NULL; handle-&gt;ipc = ipc; return 0;&#125; 它们唯一的区别就是uv_pipe_t的 ipc 参数是 true 还是 false，所有的事件都被老老实实的绑定在 libuv 上。 回到ChildProcess.prototype.spawn中，已经重置了 stdio 参数后，到了真正创建子进程的地方了，this._handle.spawn(options);，通过process_wrap.cc里的 ProcessWrap.Spawn 去创建，整个创建方法也极长，主要是对传入的参数进行处理，然后再调用uv_spawn。 1234567891011121314151617181920212223242526272829303132333435// deps/uv/src/unix/process.cint uv_spawn(uv_loop_t* loop, uv_process_t* process, const uv_process_options_t* options) &#123;#if defined(__APPLE__) &amp;&amp; (TARGET_OS_TV || TARGET_OS_WATCH) /* fork is marked __WATCHOS_PROHIBITED __TVOS_PROHIBITED. */ return UV_ENOSYS;#else // ... uv_signal_start(&amp;loop-&gt;child_watcher, uv__chld, SIGCHLD); /* Acquire write lock to prevent opening new fds in worker threads */ uv_rwlock_wrlock(&amp;loop-&gt;cloexec_lock); pid = fork(); if (pid == -1) &#123; err = UV__ERR(errno); uv_rwlock_wrunlock(&amp;loop-&gt;cloexec_lock); uv__close(signal_pipe[0]); uv__close(signal_pipe[1]); goto error; &#125; if (pid == 0) &#123; uv__process_child_init(options, stdio_count, pipes, signal_pipe[1]); abort(); &#125; /* Release lock in parent process */ uv_rwlock_wrunlock(&amp;loop-&gt;cloexec_lock); uv__close(signal_pipe[1]); // ...&#125; 通过系统层面的fork函数创建子进程，由于 fork 的特殊性，一次调用返回二次，当返回 0 的时候回执行子进程的逻辑，回去通过uv__process_child_init初始化整个子进程的上下文信息。 再回到ChildProcess.prototype.spawn中，遍历stdio，如果成员有 handle 字段，就通过createSocket为其创建一个 socket 对象 123function createSocket(pipe, readable) &#123; return net.Socket(&#123; handle: pipe, readable, writable: !readable &#125;);&#125; 无论是参数stdio是 pipe 还是 ipc 都会创建 socket，在父子进程通信的时候，父进程通过子进程暴露出来的 stdin、stdout 和 stderr 来展示子进程执行的信息，缺乏之间的数据互通性，这也是导致exec和execFile可使用的场景有限，而fork会带一个 ipc 参数给 stdio 参数（可以回过去翻翻 fork 源码），所以可以执行父子进程的通信操作，比如 send 方法等，具体的实现可以看setupChannel。 综上，Node.js 在child_process里创建进程的流程大致梳理了下，在 JavaScript 层面并没有什么复杂的，在 libuv 层面注册了很多相关的事件，有空可以研究研究。之后会写一篇关于 cluster.fork 的介绍，其实就是对 child_process.fork 更多的封装。","link":"/2020/04/06/child_process-exec-fork-spawn/"},{"title":"Eggjs Boot","text":"#PrefaceThis article will introduce the boot of Eggjs that is a Node.js web framework. It is based on Koa and can satisfy your requirement through a large of plugins and middleware, even a your own framework. It is very important to create a cluster, an agent process and some worker processes when it is running. The cluster makes it stronger. Next, we can understand it by reading the source code. Eggjs has a few major libs, egg-core、egg、egg-cluster、egg-bin、egg-scripts and so on. egg-core: it extends Koa and is as a parent object of every agent and worker. egg: it defines some actions for agent and worker, you can almost use these actions to create an app of a single process. egg-cluster: it creates a cluster and manages them. egg-scripts and Egg-bin: their job is run the whole app in a different environment. Tips: We will discuss Eggjs with basing 2.x.x version. #Scan Libs Code* The directory and the code segment are not whole content after this post, these major are only for a better explanation. egg-core123456— lib — / loader (dir) — mixin (dir) — utils (dir) egg.js lifecycle.js The above is the directory structure of egg-core.The egg.js and folder of the loader are important to point for this lib. See egg.js 12345678910111213141516171819202122232425262728293031323334const KoaApplication = require('koa')const Lifecycle = require('./lifecycle')class EggCore extends KoaApplication &#123; constructor(options = &#123;&#125;) &#123; // ... this.lifecycle = new Lifecycle(&#123; baseDir: options.baseDir, app: this, logger: this.console &#125;) const Loader = this[EGG_LOADER] assert(Loader, \"Symbol.for('egg#loader') is required\") this.loader = new Loader(&#123; baseDir: options.baseDir, app: this, plugins: options.plugins, logger: this.console, serverScope: options.serverScope, env: options.env &#125;) // ... &#125; beforeStart(scope) &#123; this.lifecycle.registerBeforeStart(scope) &#125; ready(flagOrFunction) &#123; return this.lifecycle.ready(flagOrFunction) &#125; get [EGG_LOADER]() &#123; return require('./loader/egg_loader') &#125;&#125; First, we can know why it is called that bases on Koa because EggCore extends KoaApplication. Second, it defines a few new fields in the construction function, such as lifecycle and loader. The loader field helps app for creating important feature include config、plugin、controller、extend、router、middleware、service and so on, it will load some js file in the special directory when the app is starting. Another side, both beforeStart and ready often are called when we need to write some plugins. egg123456789101112— / app— / config— / lib - / core - / messenger - / jsdoc - / loader - agent.js - application.js - egg.js - start.js- index.js There is an egg.js file that is the same name in the egg-core, but it bases on EggCore Class and extends the lifecycle field, creates new messenger field and cluster field and dumps app config info. See egg.js 123456789101112131415161718192021222324252627282930313233343536373839404142const EggCore = require('egg-core').EggCoreconst cluster = require('cluster-client')const Messenger = require('./core/messenger')class EggApplication extends EggCore &#123; constructor(options = &#123;&#125;) &#123; this.loader.loadConfig() this.messenger = Messenger.create(this) // trigger serverDidReady hook when all app workers // and agent worker is ready this.messenger.once('egg-ready', () =&gt; &#123; this.lifecycle.triggerServerDidReady() &#125;) this.ready(() =&gt; process.nextTick(() =&gt; &#123; const dumpStartTime = Date.now() this.dumpConfig() this.dumpTiming() this.coreLogger.info( '[egg:core] dump config after ready, %s', ms(Date.now() - dumpStartTime) ) &#125;) ) this.cluster = (clientClass, options) =&gt; &#123; options = Object.assign(&#123;&#125;, this.config.clusterClient, options, &#123; singleMode: this.options.mode === 'single', // cluster need a port that can't conflict on the environment port: this.options.clusterPort, // agent worker is leader, app workers are follower isLeader: this.type === 'agent', logger: this.coreLogger &#125;) const client = cluster(clientClass, options) this._patchClusterClient(client) return client &#125; &#125;&#125; See agent.js and application.js 12345678910111213141516171819202122232425262728293031// agent.jsconst EggApplication = require('./egg')const AgentWorkerLoader = require('./loader').AgentWorkerLoaderconst EGG_LOADER = Symbol.for('egg#loader')class Agent extends EggApplication &#123; constructor(options = &#123;&#125;) &#123; options.type = 'agent' super(options) this.loader.load() &#125; get [EGG_LOADER]() &#123; return AgentWorkerLoader &#125;&#125;// application.jsconst EggApplication = require('./egg')const AgentWorkerLoader = require('./loader').AppWorkerLoaderconst EGG_LOADER = Symbol.for('egg#loader')class Application extends EggApplication &#123; constructor(options = &#123;&#125;) &#123; options.type = 'application' super(options) this.loader.load() &#125; get [EGG_LOADER]() &#123; return AppWorkerLoader &#125;&#125; We can see that they override the _EGG_LOADER_ property, which uses to create a new loader field in the construction of EggCore that is their parent class. Finally, they call the load function. We have the base application code. rNext, look a few of libs for starting web app. egg-scripts and egg-binBoth these libs start the web app in a different environment. Egg-scripts is easier and more clear, uses the production environment. Egg-bin has much code for helping debug, dev, test and so on, we usually use it in the dev, debug or test environment. We almost don’t know them at most of time. 1234567891011// package.json&#123; \"scripts\": &#123; \"start\": \"env egg-scripts start\", \"dev\": \"env egg-bin dev\", \"stop\": \"egg-scripts stop\", \"debug\": \"egg-bin debug\", \"test\": \"npm run lint -- --fix &amp;&amp; npm run test-local\", \"test-local\": \"env egg-bin test\", \"cov\": \"egg-bin cov\"&#125; The scripts command of this eggjs app conforms to the above description. egg-clusterThe cluster is an important feature for Eggjs. This lib is a bridge for connecting one single agent process and many workers processes. It like a manager. 123456- / lib - / utils - agent_worker.js - app_worker.js - master.js- index.js I had written an article about egg-cluster in Chinese. I always think this is the core of Eggjs, so I will explain the whole Eggjs framework around it. #From start to getting the first requestWhat happens when we input npm run dev or npm start in the terminal? egg-scripts(prod): it can require framework by child_process.spawn and calls startCluster function. egg-bin(dev): it can require framework by child_process.fork and calls startCluster function. [parent process]: The command of running is in one process called the parent process. The system will create a new process called the master process when the parent process requires a framework.As usual, the framework is the file path of Eggjs.If you want to use a custom framework, you can add a param in the command, such as --framework { your path } Pseudo Code 123456789// egg-scripts// parent processconst spawn = require('child_process').spawn // create new processspawn('node', 'require(&#123;&#123; framework path &#125;&#125;).startCluster(...)', options))// egg-bin// parent processconst cp = require('child_process')cp.fork('require(&#123;&#123; framework path &#125;&#125;).startCluster(...)', args, options) // create new process Egg-scripts uses spawn function to require framework while egg-scripts calls fork function.The latter is a special case of the former. Egg-bin has more code than egg-scripts, these features help us for developing or debug the app. We have two processes. In general, this newly created process is called the master process. Why is the master process called birdge? 12// egg index.jsexports.startCluster = require('egg-cluster').startCluster Actually, we exec egg-cluster‘s startCluster function when we require the framework. We open index.js file in the egg-cluster lib. First, it is real enter point for whole web app. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106// index.jsconst Master = require('./lib/master')exports.startCluster = function(options, callback) &#123; new Master(options).ready(callback)&#125;// ./lib/master.jsconst ready = require('get-ready')const detectPort = require('detect-port')const Manager = require('./utils/manager')const Messenger = require('./utils/messenger')class Master extends EventEmitter &#123; constructor(options) &#123; super() this.options = parseOptions(options) this.workerManager = new Manager() this.messenger = new Messenger(this) ready.mixin(this) this.ready(() =&gt; &#123; this.isStarted = true const action = 'egg-ready' this.messenger.send(&#123; action, to: 'parent', data: &#123; port: this[REALPORT], address: this[APP_ADDRESS] &#125; &#125;) this.messenger.send(&#123; action, to: 'app', data: this.options &#125;) this.messenger.send(&#123; action, to: 'agent', data: this.options &#125;) // start check agent and worker status if (this.isProduction) &#123; this.workerManager.startCheck() &#125; &#125;) // fork app workers after agent started this.once('agent-start', this.forkAppWorkers.bind(this)) detectPort((err, port) =&gt; &#123; /* istanbul ignore if */ if (err) &#123; err.name = 'ClusterPortConflictError' err.message = '[master] try get free port error, ' + err.message this.logger.error(err) process.exit(1) &#125; this.options.clusterPort = port this.forkAgentWorker() &#125;) &#125; forkAppWorkers() &#123; // ... cluster.on('fork', worker =&gt; &#123; // ... worker.on('message', msg =&gt; &#123; if (typeof msg === 'string') msg = &#123; action: msg, data: msg &#125;; msg.from = 'app'; this.messenger.send(msg); &#125;); // ... &#125;) &#125; forkAgentWorker() &#123; // ... agentWorker.on('message', msg =&gt; &#123; if (typeof msg === 'string') msg = &#123; action: msg, data: msg &#125;; msg.from = 'agent'; this.messenger.send(msg); &#125;); // ... &#125;&#125;// the callback of ready function will be trigger after all major boots had been loaded// forkAgentWorkerconst agent = new Agent(options)agent.ready(err =&gt; &#123; if (err) return process.send(&#123; action: 'agent-start', to: 'master' &#125;)&#125;)// fork a single workerconst app = new Application(options);function startServer(err) &#123; let server; if (options.https) &#123; const httpsOptions = Object.assign(&#123;&#125;, options.https, &#123; key: fs.readFileSync(options.https.key), cert: fs.readFileSync(options.https.cert), &#125;); server = require('https').createServer(httpsOptions, app.callback()); &#125; else &#123; server = require('http').createServer(app.callback()); &#125; // emit `server` event in app app.emit('server', server); server.listen(...args);&#125;app.ready(startServer); On the other hand, this web will be constructed during creating a Master object. workerManager: it will hold on all worker porcesses. messenger: we make master a transit station that helps process for communicating (IPC). If you read more code, you can get it. I have said above that it is a bridge. I have write an article(Chinese)) about it. The Master maintains a Messenger instance (egg-cluster/lib/utils/messenger.js) EggApplication maintain the other Messenge instance （egg/lib/core/messenger.js） Both the agent and worker process base on EggApplication, them can send info to the master process creating them when calling Messenger. The master process is according to entering params to transmit to the agent or worker, you read forkAppWorkers and forkAgentWorker function in the master ready.mixin &amp; this.ready: ‘get-ready’ often is used by the official when an object need trigger a few callbacks after it whole initializes. Here it will broadcast an event to the parent, workers and then agent process, telling them that I am ok. detectPort: apply for an available port, default is 7001.If Successly, it will fork an agent process and register a callback message for new created an agent object. [agent process]: create new Agent and run loadPlugin, loadConfig, loadAgentExtend, loadContextExtend, and loadCustomAgent. loadPlugin: find all plugin, record their dir paths =&gt; this.dirs loadConfig: merge all config, the config content of the app level is more priority than the framework and the latter is more priority than the plugin. loadAgentExtend: load and merge all of the extending of agent object (app &gt; plugin &gt; core) loadContextExtend: load and merge all of the extending of context object (app &gt; plugin &gt; core) loadCustomAgent: it is important that the lifecycle of app boot will be serially triggered. This lifecycle field is defined in EggCore constructor, we can look at the whole process in the yellow background under the image.【Application Startup Configuration(official)】. It help you for better writing a few plugins. Last, all major boots had been loaded, the agent process will trigger function registered in the callback array, such as sending &#39;agent-start&#39; to the master process. [master process]: start to fork a few worker processes in accordance with specifying or using the default being CPU kernel count after the master process get &#39;agent-start&#39; message from the agent process. It will open a new relatable load, we take a single worker process example. [a single worker process]: create new Agent and run loadPlugin, loadConfig, loadApplicationExtend, loadRequestExtend, loadResponseExtend, loadContextExtend, loadHelperExtend, loadCustomApp, loadService, loadMiddleware, loadController, loadRouter, and loadCustomLoader. loadPlugin: same as the agent loadConfig: same as the agent loadApplicationExtend: same as the agent (app &gt; plugin &gt; core) loadRequestExtend: load and merge all of the extending of request object (app &gt; plugin &gt; core) loadResponseExtend: load and merge all of the extending of response object (app &gt; plugin &gt; core) loadContextExtend: same as the agent loadHelperExtend: load and merge all of the extending of helper object (app &gt; plugin &gt; core) loadCustomApp: same as the agent （app &gt; plugin） loadService: load and merge all of the extending of helper object （app &gt; plugin） loadMiddleware: load middlewares and iterate them =&gt; mw, if it conforms the middleware standard, it will be used with app.use(mw) （app &gt; plugin &gt; core） loadController: iterate all controllers’ functions =&gt; key, wrap a function, make it be a middleware function and is bound to controller.xxx.xxx (only app). This middleware will be triggered when getting a new request, the Controller is defined in the app/controller directory and the key is it’s function. 123456789function methodToMiddleware(Controller, key) &#123; return function classControllerMiddleware(...args) &#123; const controller = new Controller(this); if (!this.app.config.controller || !this.app.config.controller.supportParams) &#123; args = [ this ]; &#125; return utils.callFn(controller[key], args, controller); &#125;;&#125; loadRouter: it makes request’s path associated with the controllers’ function that has been become to middleware (only app) loadCustomLoader: load ourselves function to create some built-in objects for app object or other.Customloader [master process]: it listens to all worker processes and triggers the master’s ready once they have finished booting. send egg-ready to the parent process, the agent process, the app worker processes Last, traverse BOOTS and run serverDidReady function of each item. It is the whole boot for Eggjs framework but doesn’t include, such as restarting a worker process when it exits or disconnects, shuting down… Second, every process is alone if we have not the master. It like a bridge organizing all island, from creation to IPC. What happens when web app get an Http request? We only discuss Eggjs code in the applaction layer. :) The agent can’t deal with any request because it doesn’t listen port. All request always hand over to workers. We look at creating worker code, it will run a app.callback function and listen port when it has booted. This callback is the members of Appliaction in Koa. If server get new request, it will create a new context and handle it. In Eggjs, this handleRequest function has been overwrited. Last, the framework will iterate over all middleware under the current route including the converted controller’s function. 1234567891011121314151617181920212223242526272829303132// koa/lib/applicationclass Application extends Emitter &#123; callback() &#123; const fn = compose(this.middleware); if (!this.listenerCount('error')) this.on('error', this.onerror); const handleRequest = (req, res) =&gt; &#123; const ctx = this.createContext(req, res); return this.handleRequest(ctx, fn); &#125;; return handleRequest; &#125; handleRequest(ctx, fnMiddleware) &#123; const res = ctx.res; res.statusCode = 404; const onerror = err =&gt; ctx.onerror(err); const handleResponse = () =&gt; respond(ctx); onFinished(res, onerror); return fnMiddleware(ctx).then(handleResponse).catch(onerror); &#125;&#125;// egg/lib/applicationclass Application extends EggApplication &#123; handleRequest(ctx, fnMiddleware) &#123; this.emit('request', ctx) super.handleRequest(ctx, fnMiddleware) onFinished(ctx.res, () =&gt; this.emit('response', ctx)) &#125;&#125; In summary, we have know how to boot web app and deal with request in Eggjs. When we know it, we can easily write some plugins and middlewares to finish the business requirements.","link":"/2019/05/09/egg-boot/"},{"title":"Egg Cluster 简单介绍","text":"如果不清楚什么是Egg.js，希望能移步到它的官网简单看下。另外说它是约定大于配置的话，我只能说你真的不了解它，或者说不了解框架，哪个框架没有约定？毕竟没有规矩不成方圆，何况是逻辑性的程序呢？官方列出的特性如下： 1.提供基于 Egg 定制上层框架 的能力2.高度可扩展的插件机制3.内置多进程管理4.基于 Koa 开发，性能优异5.框架稳定，测试覆盖率高6.渐进式开发 第1条，它有那么Koa也有啊。第2条，它有，难道Koa、Express等就没有嘛？第4条，更好的补充了Koa不是更好吗？第5条，难道别的框架就不稳定了？第6条，前端鼓吹渐进式、后端也鼓吹，那究竟什么是渐进式呢？ 在我看来最吸引我的是第3条，内置多进程管理，这个在其它主流nodejs框架中是稀缺的特性，此文就简单聊聊它。 #从源码慢慢了解 egg-core: 定义了一个EggCore类，它继承KoaApplication，也就是特性中提到的第4条 基于Koa开发，性能优异 egg: 定义了一个继承于EggCore的EggApplication类，并且Application和Agent分别继承于EggApplication egg-cluster: 这个类库主要就是做多进程管理的工作 egg-cluster让Egg.js变得与众不同，看看它做了什么。 egg-cluster1234// egg-cluster index.js 唯一对外暴露的接口 startClusterexports.startCluster = function (options, callback) &#123; new Master(options).ready(callback)&#125; egg-cluster就是靠Master在管理egg里面的angent和workers（application）,另外它也是它们之间通信的中转站，看下官网给出的图解： Agent-Works怎么启动的？1234567891011121314151617181920212223242526class Master extends EventEmitter &#123; constructor(options) &#123; this.workerManager = new Manager(); this.messenger = new Messenger(this); // ... this.once('agent-start', this.forkAppWorkers.bind(this)); // ... detectPort((err, port) =&gt; &#123; // 试着找个可以用的port this.options.clusterPort = port; // 启动 agent this.forkAgentWorker(); &#125;); // ... &#125; forkAgentWorker() &#123; // ... childprocess.fork egg-cluster/lib/agent_worker.js const agentWorker = childprocess.fork(this.getAgentWorkerFile(), args, opt); // ... &#125; forkAppWorkers() &#123; // 将需要数量的 worker 一个个创建出来 // cluster.fork egg-cluster/lib/agent_worker.js 它们将监听同一个服务端口 // 创建 http或https服务 &#125;&#125; agent_worker.js主要逻辑就是创建egg类库里的Agent类，完成后发”agent-start”给父进程，触发Master的订阅创建Workers 1234// egg-cluster/lib/agent_worker.js// ...process.send(&#123; action: 'agent-start', to: 'master' &#125;); // ... Agent-Works怎么通信呢? (IPC) 在Master中维护着一个Messenger（egg-cluster/lib/utils/messenger.js）实例 EggApplication中维护了另一个Messenger（egg/lib/core/messenger.js）实例 由于Agent和Worker(Application)都继承EggApplication，它们调用Messenger的时候会send到创建它们的Master里，然后Master再根据传过来的参数send给不同的Agent或Worker，Master里的转发逻辑如下。 123456789101112131415161718192021222324// egg-cluster master.jsclass Master extends EventEmitter &#123; forkAppWorkers() &#123; // ... cluster.on('fork', worker =&gt; &#123; // ... worker.on('message', msg =&gt; &#123; if (typeof msg === 'string') msg = &#123; action: msg, data: msg &#125;; msg.from = 'app'; this.messenger.send(msg); &#125;); // ... &#125;) &#125; forkAgentWorker() &#123; // ... agentWorker.on('message', msg =&gt; &#123; if (typeof msg === 'string') msg = &#123; action: msg, data: msg &#125;; msg.from = 'agent'; this.messenger.send(msg); &#125;); // ... &#125;&#125; 1234567891011// egg messenger.jsclass Messenger extends EventEmitter &#123; send(action, data, to) &#123; sendmessage(process, &#123; action, data, to, &#125;); return this; &#125;&#125; 一条信息必定有from…to…信息 官网里提到的“多进程研发模式增强” n * m 个连接导致大量连接资源“浪费” 减少Master转发带来的额外性能消耗 另外，egg的作者们担心不当的IPC通信把Master搞挂，从而整个服务异常 所以还有一种socket通信方式（使用了另一个库cluster-client）： 将Agent作为Leader，从服务端获取数据，并做缓存 将Worker作为Follower，订阅Agent获取的数据 典型的场景有，Leader（Agent）获取disconf里的配置、获取euerka里的服务等，Follower（Worker）使用这些配置和服务。 cluster-client 源码一瞥1234567891011121314151617181920212223242526272829class ClusterClient extends Base &#123; // ... async [init]() &#123; const name = this.options.name; const port = this.options.port; let server; if (this.options.isLeader === true) &#123; server = await ClusterServer.create(name, port); if (!server) &#123; throw new Error(`create \"$&#123;name&#125;\" leader failed, the port:$&#123;port&#125; is occupied by other`); &#125; &#125; else if (this.options.isLeader === false) &#123; // wait for leader active await ClusterServer.waitFor(port, this.options.maxWaitTime); &#125; else &#123; debug('[ClusterClient:%s] init cluster client, try to seize the leader on port:%d', name, port); server = await ClusterServer.create(name, port); &#125; if (server) &#123; this[innerClient] = new Leader(Object.assign(&#123; server &#125;, this.options)); debug('[ClusterClient:%s] has seized port %d, and serves as leader client.', name, port); &#125; else &#123; this[innerClient] = new Follower(this.options); debug('[ClusterClient:%s] gives up seizing port %d, and serves as follower client.', name, port); &#125; // ... &#125;&#125; port数值就是上文开始处通过detectPort获取的clusterPort数值 然后net.create 创建TCP服务，之后所有的Leader和Follower都会走它提供的服务进行socket通信 Leader获取数据触发publish，传给订阅的Follower中 cluster-client源码是很复杂的，中间还涉及到专递数据的格式，进行数据包的解析等等，这边就不扩展介绍了，有兴趣可以自己撸源码。 #总结Egg.js的进程管理和通信自然不会像文章里说的那么简单，但大体如此。弄清楚它们的工作原理对开发程序、插件、中间件有很大的帮助，个人认为这个才是这个框架的精髓之处。","link":"/2019/01/18/egg-cluster/"},{"title":"Express Gateway","text":"为了更好的做BFF层，最近看了一些网关资料，Node.js的网关类库相对薄弱很多，主要有2个 Express Gateway Moleculer 和Lua Kong相比缺少很多刚需，比如金丝雀发布、灰度发布等等；和Java Zuul等相比，又少了很多中文文档。但是不管如何这2个是Javascript技术栈的，对于一个Node.js程序工作者来说怎能不香呢？ 今天我们主要介绍Express Gateway，背靠强大的Express社区，很多现成的中间件可以运用其中，省去了不少开发成本和风险。一些不是很大的项目或者没有时间慢慢构建底层的团队来说，我觉得可以试试。 基础概念EndpointsURL的集合，分为2类： API endpoints Service endpoints API endpoints是暴露给外网访问的，通过它将请求转发到具体的内网Service endpoints服务上。 Policies策略（policy）以Express Middleware的方式相互组织，作用在API请求和网关的响应上，包含触发条件、具体行为和参数。 Pipelines一个管道（pipeline）是API endpoints上一组策略（policies）的连接关系，管道里的策略被定义和执行。通过管道配置各种策略，一个API请求由API endpoint接受。在管道里的最后一个策略通常是代理，它将请求路由到一个service endpoint。 安装官方的Installation，可以通过CLI命令快速启动一个项目 12345npm install -g express-gatewayeg gateway createcd `Dir Path` &amp;&amp; npm start 2个重要的配置文件 system.config.yml：主要是数据库、加密方式、session等等 gateway.config.yml：主要就是路由相关的策略 在浏览器里输入 http://localhost:8080/ip ，就会被路由到 https://httpbin.org/ip 这个网站，获得一个JSON数据 123&#123; \"origin\": \"180.167.xxx.xxx\"&#125; 当然这是一个超级简单的例，用的是自带的proxy策略，如果有多个微服务节点默认使用的是round-robin做负载均衡，除此之外是static方式，只能指定死IP或URL了，显然无法满足真实的场景，很多时候需要我们自己根据实际的情况做代理开发，比如从注册中心获取微服务IP和端口做路由转发。 例子具体的代码可以在express-gateway-example查看。 使用JWT做用户登录验证 2个微服务，一个是account，另一个是banner account: 用户登录和需要验证有效身份后显示用户ID banner: 无需登录就能访问2个banner图片 在新的文件夹下（express-gateway-example），通过eg(express-gateway)和express命令工具分别生成网关项目gateway和2个微服务项目account、banner，另外新建一个存放JWT秘钥的目录secret-files，在该目录下通过下面命令创建新的秘钥 12openssl genrsa -out private.pem 512openssl rsa -in private.pem -outform PEM -pubout -out public.pem 修改网关配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// gateway.config.ymlhttp: port: 8080# admin:# port: 9876# host: localhostapiEndpoints: login: host: localhost paths: '/account/login' account: host: localhost paths: '/account/*' banner: host: localhost paths: '/banner/*'serviceEndpoints: accountSrv: url: 'http://localhost:3001' bannerSrv: url: 'http://localhost:3002'policies: - jwt - proxypipelines: login: apiEndpoints: - login policies: - proxy: - action: serviceEndpoint: accountSrv banner: apiEndpoints: - banner policies: - proxy: - action: serviceEndpoint: bannerSrv account: apiEndpoints: - account policies: - jwt: - action: jwtExtractor: 'query' jwtExtractorField: 'token' checkCredentialExistence: false secretOrPublicKeyFile: '../secret-files/public.pem' - proxy: - action: serviceEndpoint: accountSrv 3个apiEndpoints login：访问path /account/login account：访问path /account/* banner：访问path /banner/* 2个serviceEndpoints accountSrv：对应account服务，本地端口3001 bannerSrv：对应banner服务，本地端口3002 配置pipelines login和banner这2个apiEndpoints被分别简单的路由到各自的微服务上 account这个apiEndpoints除了路由外还有JWT策略，action告诉系统它将以URL query的token字段传递加密的认证信息 启动项目和访问它们 在各个目录下通过npm start分别启动它们，通过Postman GET请求http://localhost:8080/account/profile 发现返回401，可见没有通过token验证就会返回401，符合pipelines里account的配置；GET 请求http://localhost:8080/banner/ 会正常返回数据，它没有被JWT策略约束 1&#123;&quot;code&quot;:200,&quot;message&quot;:&quot;success&quot;,&quot;data&quot;:[&quot;/images/1.png&quot;,&quot;/images/2.png&quot;]&#125; 获取token POST http://localhost:8080/account/login ,它在配置中也未加JWT策略，返回如下： 12345&#123; \"code\": 200, \"message\": \"success\", \"token\": \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MjAyMCwibmFtZSI6Im1pc2VyIiwiaWF0IjoxNTgwMTQxODIwLCJleHAiOjE1ODAxNDU0MjB9.mixQa9rJqQAT2makAqWfpOCxTC-r0XussuoSrYYTb0aXcs0gMItSI5Aj6ShneX2H1BW1grXwtkrSqY8_FfhIjA\"&#125; 将token以URL query形式传参，重新访问profile接口，就正常返回用户ID了 1234567&#123; \"code\": 200, \"message\": \"success\", \"data\": &#123; \"id\": \"2020\" &#125;&#125; 上述就是一个简单的Gateway简单的例子，除开内置的一些策略（中间件）外，我们还可以自己开发一些中间件来满足具体需求——插件。 插件插件分两种： Conditions Policies 无论是上述哪一个，写好后都要注册到网关中，在gateway项目中新建plugins目录，及其子目录policies、conditions， 和manifest.js、policies/index.js、conditions/index.js文件 1234567891011// manifest.jsmodule.exports = &#123; version: '0.0.1', init: function (pluginContext) &#123; const policy = require('./policies/index.js'); pluginContext.registerPolicy(policy); const condition = require('./conditions/index.js'); pluginContext.registerCondition(condition); &#125;&#125; 通过registerPolicy和registerCondition将策略和条件注册到网关系统中，另外在system.config.yml配置文件中添加插件的配置路径 1234// system.config.ymlplugins: example: package: './plugins/manifest.js' Conditions 条件 它通过定义一个方法来判断是否执行或跳过一个策略 function (req, conditionConfig) =&gt; true/false Handler Executes on each request in current pipeline. If not matched will prevent policy from being fired 在上面的例子中，我们在apiEndpoints和pipelines都定义了一个login，其实它是accountSrv的一个特殊的存在，除了login其它的url地址都是受JWT策略约束的，按照之前的写法显得格外的冗余，我们可以通过一个Condition来做改进，重新改写gateway.config.yml 123456789101112131415161718192021222324252627282930313233// gateway.config.ymlapiEndpoints: # login: # host: localhost # paths: '/account/login' # ...pipelines: # login: # apiEndpoints: # - login # policies: # - proxy: # - action: # serviceEndpoint: accountSrv account: apiEndpoints: - account policies: - jwt: - condition: name: 'white-list' list: ['/account/login'] action: jwtExtractor: 'query' jwtExtractorField: 'token' checkCredentialExistence: false secretOrPublicKeyFile: '../secret-files/public.pem' - proxy: - action: serviceEndpoint: accountSrv 我们看到在jwt下面多了一个condition，然后在conditions/index.js里实现一个简单的URL Path 过滤 123456789module.exports = &#123; name: 'white-list', schema: &#123; $id: 'white-list', &#125;, handler: conditionConfig =&gt; req =&gt; &#123; return conditionConfig.list.indexOf(req.url) &lt; 0; &#125;&#125;; 这个Condition就完成了白名单功能了。 Policies 策略 它通过一个中间件方法对所有流入网关请求的预处理 结合上面的banner接口，我们新开发了一个v2版本的banner列表接口/banner/v2/list，为了老版本的客户端依旧能通过/banner接口访问到新的v2版本，我们需要做一个URL替换 123456789101112pipelines: banner: apiEndpoints: - banner policies: - rewrite: - action: search: '/banner' replace: '/banner/v1/list' - proxy: - action: serviceEndpoint: bannerSrv 在policies/index.js添加替换方法 123456789101112module.exports = &#123; name: 'rewrite', schema: &#123; $id: 'rewrite', &#125;, policy: (actionParams) =&gt; &#123; return (req, res, next) =&gt; &#123; req.url = req.url.replace(actionParams.search, actionParams.replace); next() &#125;; &#125;&#125;; 当我们再GET http://localhost:8080/banner/ 时候，将返回新的v2版本的数据 1234567&#123; \"code\": 200, \"message\": \"success\", \"data\": [ \"/images/v2_1.png\" ]&#125; 至此，简单的URL地址替换就完成了。 总结上诉只是Express-Gateway的一角，还有很多有趣灵活的功能值得慢慢探索。BFF层最为整个大系统的前沿征地，而网关更是前沿的前沿，配合GraphQL我相信能不断释放出JavaScript快速开发和迭代的能力，为客户端提供更好的服务和需求响应。","link":"/2020/01/22/express-gateway/"},{"title":"前端错误捕获提交错误日志","text":"为什么需要捕获？前端代码运行在客户端的浏览器里，当客户端（浏览器）出现任何问题，在没有错误日志的情况下，我们都是不知道问题发生在哪，我们只能依靠猜测或者自己不断尝试才知道，或者永远不知道问题。 客户端怎么捕获？1.通过window.onerror，可惜只能获得基础的js错误，Promise、async/await 里的错误无法捕获，它收到同源决策的影响 2.Promise 通过catch方法 3.async/await 通过 try - catch 4.Vue可以通过全局Vue.config.errorHandler去获得非Promise、async/await里的错误，可以理解为Vue里的window.onerror 不同的捕获错误用法（测试环境 chrome &amp; https://jsbin.com）window.onerror123456789window.onerror = function(message, source, lineno, colno, error) &#123; /* message：错误信息（字符串）。可用于HTML onerror=\"\"处理程序中的event。 source：发生错误的脚本URL（字符串） lineno：发生错误的行号（数字） colno：发生错误的列号（数字） error：Error对象（对象） */&#125; 12345678910111213141516window.onerror = function () &#123; console.log(arguments)&#125;let datalet info = data.info/* console 输出[object Arguments] &#123; 0: \"Uncaught TypeError: Cannot read property 'info' of undefined\", 1: \"yiveral.js\", 2: 6, 3: 17, 4: [object Error] &#123; ... &#125;&#125;*/ 虽然onerror无法捕获Promise里的错误，但是如果Promise里面是被setTimeout包裹的js还是能捕获的 12345678910111213141516171819202122232425262728293031323334353637window.onerror = function () &#123; console.log(arguments)&#125;function timer () &#123; setTimeout(function () &#123; let data let info = data.info &#125;, 100)&#125;function p() &#123; return new Promise(function (resolve, reject) &#123; timer() &#125;).catch(function (error) &#123; console.log(error) console.log('inner error') &#125;)&#125;p().then(function() &#123; console.log('running then')&#125;).catch(function(error)&#123; console.log(error) console.log('outer error')&#125;)/* console 输出[object Arguments] &#123; 0: \"Uncaught TypeError: Cannot read property 'info' of undefined\", 1: \"yiveral.js\", 2: 8, 3: 22, 4: [object Error] &#123; ... &#125;&#125;*/ Promise catchQ：如果没有catch方法，是否能捕获Promise里的错误？1234567891011121314151617181920212223242526window.onerror = function () &#123; console.log(arguments) console.log('onerror')&#125;function errorFn () &#123; let data let info = data.info&#125;function p() &#123; return new Promise(function (resolve, reject) &#123; errorFn() &#125;)&#125;try &#123; p().then(function(res) &#123; console.log('running then') &#125;)&#125; catch (e) &#123; console.log(e) console.log('try - catch')&#125;/* console 没有任何输出*/ 我们通过上面的代码发现，Promise里的错误无论在try - catch还是onerror里都无法被捕获 123456789101112131415161718192021222324252627282930313233function errorFn () &#123; let data let info = data.info&#125;function p() &#123; return new Promise(function (resolve, reject) &#123; errorFn() &#125;).catch(function (error) &#123; console.log(error) console.log('inner error') return 'return inner error' &#125;)&#125;try &#123; p().then(function(res) &#123; console.log(res) console.log('running then') &#125;).catch(function(error)&#123; console.log(error) console.log('outer error') &#125;)&#125; catch (e) &#123; console.log(e) console.log('try - catch')&#125;/* console 输出[object Error] &#123; ... &#125;\"inner error\"\"return inner error\"\"running then\"*/ 通过上面代码发现，已经被捕获的错误代码，在外层不会再被捕获而是继续执行then里的方法，可见在一条Promise链上的错误，会被之后最近的catch捕获。 async/await 通过 try - catch123456789101112131415161718192021window.onerror = function () &#123; console.log(arguments)&#125;function errorFn () &#123; let data let info = data.info&#125;function p() &#123; return new Promise(function (resolve, reject) &#123; errorFn() &#125;)&#125;(async function () &#123; let res = await p() console.log(res)&#125;)()/* console 没有任何输出*/ 我们通过上面的代码发现，Promise构造函数里的错误并没有被onerror捕获 1234567891011121314151617181920212223window.onerror = function () &#123; console.log(arguments)&#125;function errorFn () &#123; let data let info = data.info&#125;function p() &#123; return new Promise(function (resolve, reject) &#123; resolve('resolve') &#125;)&#125;(async function () &#123; let res = await p() console.log('get res') errorFn()&#125;)()/* console 输出get res*/ 虽然Promise正常执行，但是当后续的代码出错onerror依旧没有被捕获 123456789101112131415161718192021222324function errorFn () &#123; let data let info = data.info&#125;function p() &#123; return new Promise(function (resolve, reject) &#123; errorFn() &#125;)&#125;(async function () &#123; try &#123; let res = await p() console.log(res) &#125; catch (e) &#123; console.log(e) console.log('try - catch') &#125;&#125;)()/* console 输出[object Error] &#123; ... &#125;\"try - catch\"*/ try - catch捕获了 1234567891011121314151617181920212223242526272829function errorFn () &#123; let data let info = data.info&#125;function p() &#123; return new Promise(function (resolve, reject) &#123; errorFn() &#125;).catch(function (error) &#123; console.log(error) console.log('inner error') return 'return inner error' &#125;)&#125;(async function () &#123; try &#123; let res = await p() console.log(res) &#125; catch (e) &#123; console.log(e) console.log('try - catch') &#125;&#125;)()/* console 输出[object Error] &#123; ... &#125;\"inner error\"\"return inner error\"*/ 从上面代码我们知道，如果Promise构造函数里的错误被它自己catch的话，那么 async/await 后续的 try - catch将不再对它捕获 Vue.config.errorHandler12345Vue.config.errorHandler = function (err, vm, info) &#123; // handle error // `info` 是 Vue 特定的错误信息，比如错误所在的生命周期钩子 // 只在 2.2.0+ 可用&#125; 指定组件的渲染和观察期间未捕获错误的处理函数。这个处理函数被调用时，可获取错误信息和 Vue 实例。 我们该如何去理解官方对errorHandler的解释呢？通过 vue-cli构建工具，创建一个非常基础的vue项目，做一些实验。 测试代码库：https://github.com/miser/vue-capture-error 在main.js 1234Vue.config.errorHandler = function (err, vm, info) &#123; console.log(arguments) console.log('vue errorHandler')&#125; 在App.vue 12345678910111213141516171819&#123; // ... created () &#123; this.normal() &#125;, methods: &#123; normal () &#123; let data let info = data.info &#125; &#125; // ... &#125;/* 刷新页面 console 输出0: TypeError: Cannot read property 'info' of undefined at VueComponent.normal …1: VueComponent &#123;_uid: 1, _isVue: true, $options: &#123;…&#125;, _renderProxy: Proxy, _self: VueComponent, …&#125;2: \"created hook*/ 从上面代码可以看出，errorHandler确实可以满足我们的需求，在一个统一的地方捕获代码的错误，但是真的如此吗？上文也提到errorHandler和window.onerror类似，那么当我们使用Promse或者async/await时会不会得愿以偿。 js中的异步很大一部分来自网络请求，那么在这我们用 axios （它做了一层ajax与Promise之间的封装）。 main.js里添加 1234567891011121314const request = axios.create()request.interceptors.response.use(response =&gt; &#123; return response&#125;)Vue.request = (args) =&gt; &#123; return new Promise((resolve, reject) =&gt; &#123; request(args).then(res =&gt; &#123; resolve(res) &#125;).catch(err =&gt; &#123; reject(err) &#125;) &#125;)&#125; 在App.vue 123456789101112131415&#123; // ... created () &#123; this.fetch1() &#125;, methods: &#123; fetch1 () &#123; Vue.request('https://api1.github.com/') .then(response =&gt; &#123; console.log(response) &#125;) &#125; &#125; // ... &#125; api.github.com 会返回 github的api列表，当我们拼错域名，比如上面代码中的api1.github.com时，那肯定是无法获得我们想要的，可是errorHandler并没有获得该错误，不过幸好，我们可以在全局统一的Vue.request里的catch方法去统一捕获网络层面的错误。那如果是非网络层面的呢？比如数据请求回来了，但是绑定数据的时候，后端因为业务的修改等原因并没有返回我们需要的字段，造成Promise.then方法的业务处理错误。 在App.vue 12345678910111213141516&#123; // ... created () &#123; this.fetch2() &#125;, methods: &#123; fetch2 () &#123; Vue.request('https://api.github.com/') .then(response =&gt; &#123; let data = response.data let info = data.api.info &#125;) &#125; &#125; // ... &#125; 上诉代码运行后，errorHandler同样未能捕获错误，从vue的issue里面去查询关于捕获Promise或者async/await时，会得到作者的答复: https://github.com/vuejs/vue/issues/6551 Vue cannot capture errors that are thrown asynchronously, similar to how try… catch won’t catch async errors. It’s your responsibility to handle async errors properly, e.g. using Promise.catch — @yyx990803 那么该怎么办，不可能每个地方都加Promise.catch方法吧！ https://github.com/vuejs/vue/issues/7653 @Doeke 在这个地方给出一个解决方案，通过全局mixin，给那些Promise方法外面包一层Promise，在这个外层Promise链上catch里面的错误，不过这样需要做代码的约定，就是原来的方法需要返回一个Promise对象。 main.js里添加@Doeke的思路 12345678910111213141516171819202122232425262728Vue.mixin(&#123; beforeCreate: function () &#123; const methods = this.$options.methods || &#123;&#125; Object.entries(methods).forEach(([key, method]) =&gt; &#123; if (method._asyncWrapped) return const wrappedMethod = function (...args) &#123; const result = method.apply(this, args) const resultIsPromise = result &amp;&amp; typeof result.then === 'function' if (!resultIsPromise) return result return new Promise(async (resolve, reject) =&gt; &#123; try &#123; resolve(await result) &#125; catch (error) &#123; if (!error._handled) &#123; const errorHandler = Vue.config.errorHandler errorHandler(error) error._handled = true &#125; reject(error) &#125; &#125;) &#125; wrappedMethod._asyncWrapped = true methods[key] = wrappedMethod &#125;) &#125;&#125;) 在App.vue 123456789101112131415161718192021222324&#123; // ... created () &#123; this.fetch2() this.fetch3() &#125;, methods: &#123; fetch2 () &#123; Vue.request('https://api.github.com/') .then(response =&gt; &#123; let data = response.data let info = data.api.fetch2 &#125;) &#125;, fetch3 () &#123; return Vue.request('https://api.github.com/') .then(response =&gt; &#123; let data = response.data let info = data.api.fetch3 &#125;) &#125; &#125; // ... &#125; 通过运行并观察console打印可以看出，fetch3的错误被errorHandler捕获，而fetch2的错误并没有。 那么Promise里的错误统一捕获的问题差不多应该解决了，那么async/await的呢？ 在App.vue 123456789101112131415161718192021&#123; // ... created () &#123; this.fetch4() this.fetch5() &#125;, methods: &#123; async fetch4 () &#123; let response = await Vue.request('https://api.github.com/') let data = response.data let info = data.api.fetch4 &#125;, async fetch5 () &#123; let response = await Vue.request('https://api.github.com/') let data = response.data let info = data.api.fetch5 return response &#125; &#125; // ... &#125; fetch4并没有返回Promise，fetch5返回的也不是Promise对象，但是当运行的时候我们会发现fetch4和fetch5的错误信息都被捕获了，这是为什么呢？因为async/await本身就是Promise的语法糖，在 babeljs 官网的 “Try it out” 尝试用 async/await，你会发现最后编译后的代码就是在外包了一层Promise。 在哪里捕获更为优雅？（尽量以更少的代码覆盖大部分或者全部代码）网络层：可以在axios.create创建的实例中 逻辑层：非Promise本身就会被errorHandler捕获；Promise相关的可以通过全局mixin给返回Promise对象的方法做一个外层包装，统一catch并调用errorHandler处理（这个方法的是否有副作用还需要研究!） 捕获的错误存放在哪？# 自己简易服务 ？ 感觉成本很大（人力和工时） # 官方推荐的 Sentry 注册后安装官方的JS SDK 1npm install raven-js --save 修改main.js 1234567891011121314151617181920212223// ...import Raven from 'raven-js'import RavenVue from 'raven-js/plugins/vue'Raven .config('https://1dfc5e63808b41058675b4b3aed4cfb6@sentry.io/1298044') // sentry token .addPlugin(RavenVue, Vue) .install()Vue.config.errorHandler = function (err, vm, info) &#123; Raven.captureException(err)&#125;Vue.request = (args) =&gt; &#123; return new Promise((resolve, reject) =&gt; &#123; request(args).then(res =&gt; &#123; resolve(res) &#125;).catch(err =&gt; &#123; Raven.captureException(err) reject(err) &#125;) &#125;)&#125;// ... 修改App.vue （我们从最普通的js测试起）12345678910// ...created () &#123; this.normal() // this.fetch1() // this.fetch2() // this.fetch3() // this.fetch4() // this.fetch5()&#125;// ... 打开sentry页面查看我们通过上面2张图片可以看出，sentry自带一个简单的issue管理功能，此外详情页面的错误栈已经方便我们知道问题出在哪里了。 测试fetch1的ajax请求错误 除了fetch2无法被捕获外（之前提过，它没有返回Promise对象），其它的都能被捕获。不过Promise和async/await的错误栈比较少。尤其是Promise.then里的错误，如下2张图的对比： 除了默认的数据的收集外，还能收集一些其他数据，比如用户信息 1234Raven.setUser(&#123; name: 'miser name', id: 'miser id' &#125;) 我们测试了代码未被压缩的情况，如果代码压缩了呢？ 显然我们不能直观的获得错误定位，不过sentry提供SourceMaps存储服务，它能方便的debug被压缩的代码。 我们可以通过webpack-sentry-plugin工具将整个上传过程写进webpack里，因为我们的实验环境是vue3，所以我们创建一个vue.config.js文件 1234567891011121314const SentryPlugin = require('webpack-sentry-plugin')module.exports = &#123; configureWebpack: &#123; plugins: [ new SentryPlugin(&#123; organization: 'fe-org', // 组织名称 类似公司名吧（一个用户下可以有多个组织） project: 'popcorn-vue', // 项目名称 （一个组织下可以有多个项目） apiKey: '17c7d61a800f495c803196e2c02cadeb1b41454247db4f06a5c54193510da150', release: '1.2.4-beta' // 发布后的代码和这个对应，可以找到这个sourcemaps &#125;) ] &#125;&#125; 修改main.js123456Raven .config('https://1dfc5e63808b41058675b4b3aed4cfb6@sentry.io/1298044', &#123; release: '1.2.4-beta' // 新增 &#125;) .addPlugin(RavenVue, Vue) .install() 1npm run build 查看sentry里popcorn-vue项目中的版本 我们打开build完的index.html，虽然错误成功捕获但依旧和上图的一样，无法被SourceMaps解析，大概的原因是js和js.map的目录结构问题。 这个issue https://github.com/getsentry/sentry-electron/issues/54 是一个很经典的例子，它犯了2个错误 – 仅仅传了js.map而没有传被压缩的js文件，它们应该一一对应的上传到服务器上– js和js.map目录路径不匹配 这2个原因都会导致无法正常解析被压缩的文件。 那么不直接通过浏览器打开index.html（file:///**/vue-capture-error/dist/index.html），通过nginx去模拟正式环境。12brew install nginxnginx 将build出的代码dist拷贝到nginx默认目录下 /usr/local/var/www/，打开浏览器http://localhost:8080 回到sentry中查看新的错误记录","link":"/2018/10/23/js-capture-error/"},{"title":"Lighthouse 流程和架构分析","text":"背景随着公司业务的不断扩展 ，系统也变得越来越臃肿，需要被不断的拆分，引进诸如微前端这样的框架，开发人员也不断的扩充，甚至有不同办公地点的同事协作开发。除了基本的开发规范外，也需要有一套完善的监控来测试和记录每次代码提交是否比之前版本存在性能不足等问题，在 CI 阶段发现问题，提早解决避免上线后带来性能损失而流失用户。团队成员也能在工作中不断的成长、驱动、交付出优质的应用。 前端经常要关注的几个指标：First Contentful Paint：浏览器首次绘制文本、图片（包含背景图）、非白色的 canvas 或 SVG 的时间节点。反映了网络的可用性和页面资源是否庞大导致传输时间过长。 First Meaningful Paint：页面的“主要内容”开始出现在屏幕上的时间点，测量用户加载体验的主要指标。反映了是否太多非重要资源加载或执行的优先级高于主要的呈现资源。 First CPU Idle：页面主线程首次可以触发 input 操作，通常叫做最小可交互时间。 Time to Interactive：页面完全达到可交互状态的时间点。 Lighthouse 介绍 是一个开源的自动化工具，用于改进网络应用的质量。 您可以将其作为一个 Chrome 扩展程序运行，或从命令行运行。 您为 Lighthouse 提供一个您要审查的网址，它将针对此页面运行一连串的测试，然后生成一个有关页面性能的报告。 原理分析 Driver： 和 Chrome 交互的对象 Gatherers： 收集网页的一些基础信息，用于后续的 Audit Artifacts： 一系列 Gatherers 的信息集合 Audit： 测试单个功能/优化/指标。用 Artifacts 作为输入，计算出该项指标的得分，生成Lighthouse 标准的数据对象 Report： 根据 Lighthouse 标准的数据对象生成可视化页面 Lighthouse 通过 Driver 模块用 DevTools Protocol 与 Chrome 通信，按照需求对其进行操作，在 Gatherers 模块收集一些信息（artifacts）,在 Audits 模块中进行计算，得到最终打分结果，生成 LHR 根式的报告，渲染成 HTML 文件。 Lighthouse CI官方示例 1234567891011name: CIon: [push]jobs: lighthouseci: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - uses: actions/setup-node@v1 - run: npm install &amp;&amp; npm install -g @lhci/cli@0.4.x - run: npm run build - run: lhci autorun --upload.target=temporary-public-storage npm run build： 将静态资源打包，一般打包后的资源会存放在 dist 目录里 lhci autorun： 常用命令，如其字面意思，自动完成整个测试流程，在它里面包含了healthcheck、collect、assert、upload命令 collect 命令源码分析 @lhci/cli 版本 0.4.x 123456789101112131415161718192021222324252627282930313233// autorunasync function runCommand(options) &#123; // 执行 healthcheck const healthcheckStatus = runChildCommand(\"healthcheck\", [ ...defaultFlags, \"--fatal\", ]).status; // 执行 collect，重点命令 const collectStatus = runChildCommand(\"collect\", [ ...defaultFlags, ...collectArgs, ]).status; // 默认不执行 assert 命令， 需要 assert 参数 并且 没有 upload 参数 if ( ciConfiguration.assert || (!ciConfiguration.assert &amp;&amp; !ciConfiguration.upload) ) &#123; const assertStatus = runChildCommand(\"assert\", [ ...defaultFlags, ...assertArgs, ]).status; &#125; // 默认不执行 upload 命令， 例子中有 upload 参数 会执行它 if (ciConfiguration.upload) &#123; const uploadStatus = runChildCommand(\"upload\", defaultFlags).status; if (options.failOnUploadFailure &amp;&amp; uploadStatus !== 0) process.exit(uploadStatus); if (uploadStatus !== 0) process.stderr.write(`WARNING: upload command failed.\\n`); &#125;&#125; 从上述代码中可以很直观看到 autorun 里面包含的命令 healthcheck 一些检查，比如是否安装了 Chrome、客户端版本和服务端版本是否一致等等 collect 重要命令，它的整个流程基本涵盖了架构图，从信息的采集到生成报告 assert 性能分析是否通过，会有相关的提示 upload 上传报告到指定的服务器，上面例子的上传目标是 temporary-public-storage，一个 google 提供的临时公共服务器 12345678910111213141516171819202122232425262728293031323334async function runCommand(options) &#123; if (!options.additive) clearSavedReportsAndLHRs(); checkIgnoredChromeFlagsOption(options); const puppeteer = new PuppeteerManager(options); // 检查是否有 staticDistDir 参数（默认是dist、build或public，也可以通过--static-dist-dir指定） // staticDistDir是打包后的静态资源目录 // 有 =&gt; 创建 express server， 将静态资源加载进服务中（一般都是有的，除非手动关闭） // 没 =&gt; 执行 startServerCommand，开发者自己创建一个服务 // 没有服务支持，浏览器无法打开页面进行测试 const &#123; urls, close &#125; = await startServerAndDetermineUrls(options); for (const url of urls) &#123; // 如果有 puppeteerScript 参数，那么会出触发该脚本 await puppeteer.invokePuppeteerScriptForUrl(url); // await runOnUrl(url, options, &#123; puppeteer &#125;); &#125;&#125;async function runOnUrl(url, options, context) &#123; const runner = getRunner(options); // // 默认执行3次 for (let i = 0; i &lt; options.numberOfRuns; i++) &#123; // 每次新开一个Node.js进程 调用 lighthouse-cli const lhr = await runner.runUntilSuccess(url, &#123; ...options, settings, &#125;); saveLHR(lhr); // 保存 lighthouse result 数据 &#125;&#125; puppeteer：一个通过 DevTools Protocol 操控 Headless Chrome 的 Node.js 类库 numberOfRuns 默认是 3，会分别开启 3 个 Node.js 进程各走一次流程，最后在 .lighthouseci 目录下生成 3 对 lhr-xxx.json 和 lhr-xxx.html 文件（前者是分析结果，后者是渲染的网页），及一个 assertion-results.json 文件 runUntilSuccess 开始执行 lighthouse-cli 里的逻辑 1234567891011121314151617// lighthouse-cli 部分代码async function runLighthouse(url, flags, config) &#123; let launchedChrome; // 通过 chrome-launcher 启动一个 headless Chrome launchedChrome = await getDebuggableChrome(flags); flags.port = launchedChrome.port; // 需要知道该Chrome端口号，为了之后的 websocket 通信 // lighthouse-core/index.js const runnerResult = await lighthouse(url, flags, config); if (runnerResult) &#123; await saveResults(runnerResult, flags); &#125; return runnerResult;&#125; 在 lighthouse-cli 中主要就是启动一个 headless Chrome（无界面的 Chrome）,后续交由 lighthouse-core 核心模块完成。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// lighthouse-core/index.jsasync function lighthouse(url, flags = &#123;&#125;, configJSON, connection) &#123; // 将自定义配置和默认配置做合并 // 根据配置信息创建大量继承Gatherer的对象，有3个方法beforePass、pass、afterPass const config = generateConfig(configJSON, flags); // ChromeProtocol 封装了和 Chrome 通信的 websocket const connection = connection || new ChromeProtocol(flags.port, flags.hostname); // 收集 Gather 和计算 Audit 的核心方法 return Runner.run(connection, &#123; url, config &#125;);&#125;async function run(connection, runOpts) &#123; // 从浏览器中获取所有的 artifacts artifacts = await Runner._gatherArtifactsFromBrowser( requestedUrl, runOpts, connection ); // 根据获取的artifacts，计算需要的 audits，得出结果 const auditResults = await Runner._runAudits( settings, runOpts.config.audits, artifacts, lighthouseRunWarnings ); const lhr = &#123; // ... &#125;; // 按照 lhr 格式生成报告 lhr.i18n.icuMessagePaths = i18n.replaceIcuMessageInstanceIds( lhr, settings.locale ); const report = generateReport(lhr, settings.output); return &#123; lhr, artifacts, report &#125;;&#125;async function _gatherArtifactsFromBrowser( requestedUrl, runnerOpts, connection) &#123; const driver = runnerOpts.driverMock || new Driver(connection); const gatherOpts = &#123; driver, requestedUrl, settings: runnerOpts.config.settings, &#125;; // 收集 Gather，生成结果集合 artifacts const artifacts = await GatherRunner.run( runnerOpts.config.passes, gatherOpts ); return artifacts;&#125; 上述代码的逻辑非常清晰，就是根据现有数据（artifacts），计算出结果数据（audits），生成报告。 如何得到 artifacts 这些信息的呢？12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// gather-runner.jsasync function run(passConfigs, options) &#123; const artifacts = &#123;&#125;; const driver = options.driver; // 和 Chrome 进行连接 await driver.connect(); // 加载个 about:blank 空白页面 await GatherRunner.loadBlank(driver); // 创建 artifacts // 一些基础信息，比如userAgent、移动还是桌面emulate const baseArtifacts = await GatherRunner.initializeBaseArtifacts(options); // 通过一定数量的字符串拼接计算出待测试驱动的性能 baseArtifacts.BenchmarkIndex = await options.driver.getBenchmarkIndex(); // 将环境配置好 await GatherRunner.setupDriver(driver, options); // passConfigs 就是 需要收集的Gather集合 // runPass是一个很长的周期，真正开始做数据分析的方法 for (const passConfig of passConfigs) &#123; const passContext = &#123; driver, url: options.requestedUrl, settings: options.settings, passConfig, baseArtifacts, LighthouseRunWarnings: baseArtifacts.LighthouseRunWarnings, &#125;; // loadBlank =&gt; setupPassNetwork =&gt; cleanBrowserCaches // =&gt; beforePass // gather 对象对外暴露的接口 // =&gt; beginRecording // =&gt; loadPage // =&gt; pass // gather 对象对外暴露的接口 // =&gt; endRecording // =&gt; afterPass // gather 对象对外暴露的接口 // =&gt; collectArtifacts const passResults = await GatherRunner.runPass(passContext); // 将所有结果挂在 artifacts 对象上 Object.assign(artifacts, passResults.artifacts); &#125; return &#123; ...baseArtifacts, ...artifacts &#125;; // Cast to drop Partial&lt;&gt;.&#125;// Gatherer 基类class Gatherer &#123; get name() &#123; return this.constructor.name; &#125; beforePass(passContext) &#123;&#125; pass(passContext) &#123;&#125; afterPass(passContext, loadData) &#123;&#125;&#125; runPass 是一个重要的生命周期，如果要给 Lighthouse 写自定义的扩展，必须要了解它。其实就是模拟人的行为，打开空网页（loadBlank），设置网络参数（setupPassNetwork），情况缓存（cleanBrowserCaches），beforePass（注入页面加载前注入脚本获取关键信息），beginRecording（页面加载前记录 devtoolsLog 和 trace），pass（页面加载中），endRecording（页面加载结束记录 devtoolsLog 和 trace），afterPass（页面加载结束注入脚本获取关键信息），collectArtifacts（收集相关信息）。其中，beforePass、pass 和 afterPass 在写自定义 gather 时可以注入脚本获取自己需要的信息的，非常有用。最后将收集的信息挂载到 artifacts 上。系统内置的信息收集类都在 lighthouse-core 下的 gather/gatherers 目录里。 以收集图片信息的 ImageElements 为例，它对外暴露了 afterPass 接口，是一个经典应用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// image-elements.jsclass ImageElements extends Gatherer &#123; async afterPass(passContext, loadData) &#123; const driver = passContext.driver; const indexedNetworkRecords = loadData.networkRecords.reduce( (map, record) =&gt; &#123; if ( /^image/.test(record.mimeType) &amp;&amp; record.finished &amp;&amp; record.statusCode === 200 ) &#123; map[record.url] = record; &#125; return map; &#125; ); const expression = `(function() &#123; $&#123;pageFunctions.getElementsInDocumentString&#125;; // define function on page $&#123;getClientRect.toString()&#125;; $&#123;getHTMLImages.toString()&#125;; $&#123;getCSSImages.toString()&#125;; $&#123;collectImageElementInfo.toString()&#125;; return collectImageElementInfo(); &#125;)()`; const elements = await driver.evaluateAsync(expression); const top50Images = Object.values(indexedNetworkRecords) .sort((a, b) =&gt; b.resourceSize - a.resourceSize) .slice(0, 50); const imageUsage = []; for (let element of elements) &#123; // ... // 在Chrome注入并执行 determineNaturalSize 方法，获取图片的原始宽和高 &#125; return imageUsage; &#125;&#125;function determineNaturalSize(url) &#123; return new Promise((resolve, reject) =&gt; &#123; const img = new Image(); img.addEventListener(\"error\", (_) =&gt; reject(new Error(\"determineNaturalSize failed img load\")) ); img.addEventListener(\"load\", () =&gt; &#123; resolve(&#123; naturalWidth: img.naturalWidth, naturalHeight: img.naturalHeight, &#125;); &#125;); img.src = url; &#125;);&#125; 所有 afterPass 方法是在页面加载完后执行的，所以会比 beforePass 多一个loadData参数，记录了网络加载的数据，比如，图片。 在 ImageElements 中 先找出所有正常加载的图片 expression，定义一个闭包，将相关需要用到的方法通过字符串的形式拼接起来，再用 driver.evaluateAsync 将它们注入到 Chrome, 并执行 按照尺寸大小排序，获取最大的前 50 个图片信息 elements 和 top50Images，进行相关的逻辑处理获取图片的原始尺寸，最后返回结果集 imageUsage 从上述代码我们可以知道，将 JavaScript 方法通过 driver.evaluateAsync 注入到 Chrome 里并执行，收集页面的信息。 有了信息，该如何计算呢？系统内置的计算类都在 lighthouse-core 下的 audits 目录里。整体的流程和 gather 很像，都是遍历配置里的集合，然后触发暴露的方法（此处是 audit）,然后合并输出，大概过程如下。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 接上面 lighthouse-core/index.js 里的const auditResults = await Runner._runAudits( settings, runOpts.config.audits, artifacts, // 之前收集的信息 lighthouseRunWarnings);async function _runAudits(settings, audits, artifacts, runWarnings) &#123; // 迭代配置里生成的audits对象集合 for (const auditDefn of audits) &#123; const auditResult = await Runner._runAudit( auditDefn, artifacts, sharedAuditContext, runWarnings ); auditResults.push(auditResult); &#125; return auditResults;&#125;async function _runAudit( auditDefn, artifacts, sharedAuditContext, runWarnings) &#123; const audit = auditDefn.implementation; let auditResult; const auditOptions = Object.assign( &#123;&#125;, audit.defaultOptions, auditDefn.options ); const auditContext = &#123; options: auditOptions, ...sharedAuditContext, &#125;; // 调用 audit 方法 const product = await audit.audit(narrowedArtifacts, auditContext); auditResult = Audit.generateAuditResult(audit, product); return auditResult;&#125;class Audit &#123; // Audit 基类内容比较多，主要对外暴露的是 audit 方法，子类必须重写 static audit(artifacts, context) &#123; throw new Error(\"audit() method must be overriden\"); &#125;&#125; 我们依旧以图片的为例。 1234567891011121314151617181920212223242526// /audits/image-size-responsive.jsclass ImageSizeResponsive extends Audit &#123; static audit(artifacts) &#123; const DPR = artifacts.ViewportDimensions.devicePixelRatio; const results = Array.from(artifacts.ImageElements) // 从 gather ImageElements里收集的信息 .filter(isCandidate) // 过滤掉没用的图片 .filter(image =&gt; !imageHasRightSize(image, DPR)) // 算出图片尺寸是否过大 .filter( image =&gt; isVisible(image.clientRect, artifacts.ViewportDimensions) // 算出图片是否在可是区域 ) .map(image =&gt; getResult(image, DPR)); // 获取图片的相关信息，组成集合 const headings = [ // ... ]; const finalResults = // ... return &#123; // 如果集合中没有含有过大并且在可视区域的图片，那么为true // 之后，所有 audits 中的 score 为 true 将被累加其数量，并按照百分比算出相关得分 score: Number(results.length === 0), details: Audit.makeTableDetails(headings, finalResults) &#125;; &#125;&#125; gather 和 audit 是核心的流程和概念，上文我们已经简单的分析了整个代码，从 2 者的目录结构图也不难发现 audit 数量远远大于 gather，这也是为什么 2 者分开的重要原因，audit 通过 artifacts 去获取自己想要的数据再进行逻辑计算，增加了 gather 数据的复用性，和各自的扩展性，各个模块的测试也变得容易。 总结Lighthouse 是一个非常有用的前端性能评测工具，本文主要讲的基础概念，后续将介绍 puppeteer 的使用，如何利用 gather 和 audit 自定义性能监控指标。另外对内置的 gather 和 audit 研究也能极大争强自己对前端的认知，对 Driver 的学习能增加对 DevTools 和 Chrome 的新认知，非常值得深挖。","link":"/2020/07/07/lighthouse/"},{"title":"CSS、JS文件对网页的影响","text":"我们常说浏览器是单线程的，那么我们在加载资源的时候页面是在等待加载完成呢？还是继续执行后续的操作？加载不同资源对浏览器的操作会有相同响应吗？我们可以通过一个一个简单的实验测试来了解。 环境所有资源均在localhost，浏览器chrome 69，不同浏览器或版本会有少许不同 – css css1.css 2秒后返回 body { background-color: #444 } css2.css 立即返回 body { font-size: 50px;font-weight: bold; } – js js1.js 1秒后返回 console.log(“js1.js loaded”) js2.js 立即返回 console.log(“js2.js loaded”) js3.js 3秒后返回 console.log(“js2.js loaded”) – image img1.png 3秒后 返回一张黄色js图片 img2.png 立即返回一张 nodejs图片 服务器端代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263const Koa = require('koa')const Router = require('koa-router')const views = require('koa-views')const fs = require('fs')const app = new Koa()const router = new Router()app.use(views(__dirname + '/views'))router.get('/', async (ctx, next) =&gt; &#123; await ctx.render('index.html')&#125;)router.get('/css1.css', async ctx =&gt; new Promise(resolve =&gt; &#123; setTimeout(function () &#123; ctx.set('Content-Type', 'text/css') ctx.body = 'body &#123; background-color: #444 &#125;' resolve() &#125;, 1000 * 2)&#125;))router.get('/css2.css', async ctx =&gt; &#123; ctx.set('Content-Type', 'text/css') ctx.body = 'body &#123; font-size: 50px;font-weight: bold; &#125;'&#125;)router.get('/js1.js', async ctx =&gt; new Promise(resolve =&gt; &#123; setTimeout(function () &#123; ctx.body = 'console.log(\"js1.js loaded\")' resolve() &#125;, 1000)&#125;))router.get('/js2.js', async ctx =&gt; &#123; ctx.body = 'console.log(\"js2.js loaded\")'&#125;)router.get('/js3.js', async ctx =&gt; new Promise(resolve =&gt; &#123; setTimeout(function () &#123; ctx.body = 'console.log(\"js3.js loaded\")' resolve() &#125;, 1000 * 3)&#125;))router.get('/img1.png', async ctx =&gt; new Promise(resolve =&gt; &#123; setTimeout(function () &#123; ctx.set('Content-Type', 'image/png; charset=UTF-8') ctx.body = fs.createReadStream('1.png') resolve() &#125;, 1000 * 3)&#125;))router.get('/img2.png', async ctx =&gt; &#123; ctx.set('Content-Type', 'image/png; charset=UTF-8') ctx.body = fs.createReadStream('2.png')&#125;)app .use(router.routes()) .use(router.allowedMethods())app.listen(3000) 实验一： CSS加载是否影响DOM解析index.html 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('test') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; setTimeout(function() &#123; const el = document.getElementById('app') console.log(el) &#125;, 0) &lt;/script&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css1.css\" /&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css2.css\" /&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt; &lt;img style=\"width: 100px\" src=\"/img1.png\" /&gt; &lt;img style=\"width: 100px\" src=\"/img2.png\" /&gt;&lt;/body&gt;&lt;script type=\"text/javascript\"&gt; console.timeEnd('test')&lt;/script&gt;&lt;/html&gt;&lt;!-- console 输出app元素对象test: 1947.620849609375ms--&gt; 从控制台的输出可以看到 app 元素会被正确输出，2秒左右再输出 test 的时间，可见CSS加载并不会阻碍DOM解析。 实验二： CSS加载是否影响JS执行和DOM渲染index.html 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('test') &lt;/script&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css1.css\" /&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css2.css\" /&gt; &lt;script type=\"text/javascript\" src=\"/js1.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"/js2.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt; &lt;img style=\"width: 100px\" src=\"/img1.png\" /&gt; &lt;img style=\"width: 100px\" src=\"/img2.png\" /&gt;&lt;/body&gt;&lt;script type=\"text/javascript\"&gt; console.timeEnd('test')&lt;/script&gt;&lt;/html&gt;&lt;!-- console 输出js1.js loadedjs2.js loaded(index):17 test: 1921.02099609375ms--&gt; 当打开index.html页面后，会发现所有资源均同时发起了请求，页面会先处于白屏加载状态（DOM无法渲染），当2秒（左右）后页面除img1.png未渲染外，其它样式和图片均渲染。 从控制台的输出可以看出，虽然js比css快1秒左右加载完毕，但是此刻是处于阻塞状态并没有执行，当css加载完成后，才从上至下的执行（虽然js2.js比js1.js早加载好，但是执行的时候还是从上至下的），当css1.css加载完成后，页面立即渲染，图片img1.png晚1秒左右显示。可见CSS加载会阻碍JS执行和DOM的渲染。 实验三： JS加载是否影响DOM解析和渲染index.html 123456789101112131415161718192021222324252627282930&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('test') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; setTimeout(function() &#123; const el = document.getElementById('app') console.log(el) &#125;, 0) &lt;/script&gt; &lt;script type=\"text/javascript\" src=\"/js3.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt; &lt;img style=\"width: 100px\" src=\"/img1.png\" /&gt; &lt;img style=\"width: 100px\" src=\"/img2.png\" /&gt;&lt;/body&gt;&lt;script type=\"text/javascript\"&gt; console.timeEnd('test')&lt;/script&gt;&lt;/html&gt;&lt;!-- console 输出nulljs3.js loadedtest: 2943.9951171875ms--&gt; 我们仅引入一个js3.js文件，设置它的返回时间为3秒，从控制台的输出可以看到 app 元素没有被正确输出（输出null），3秒左右再输出 test 的时间，可见JS加载会阻碍DOM解析，既然解析都被影响自然必定影响渲染了。 实验四： DOM的DOMContentLoaded和onLoad事件index.html 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('test') console.time('testDOMContentLoaded') console.time('testonload') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; document.addEventListener('DOMContentLoaded', function () &#123; console.timeEnd('testDOMContentLoaded') &#125;, false) window.onload = function () &#123; console.timeEnd('testonload') &#125; &lt;/script&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css1.css\" /&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"/css2.css\" /&gt; &lt;script type=\"text/javascript\" src=\"/js1.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"/js2.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt; &lt;img style=\"width: 100px\" src=\"/img1.png\" /&gt; &lt;img style=\"width: 100px\" src=\"/img2.png\" /&gt;&lt;/body&gt;&lt;script type=\"text/javascript\"&gt; console.timeEnd('test')&lt;/script&gt;&lt;/html&gt;&lt;!-- console 输出js1.js loadedjs2.js loadedtest: 1955.489990234375mstestDOMContentLoaded: 1956.044189453125mstestonload: 2964.078857421875ms--&gt; 我们通过控制台会发现 testDOMContentLoaded 会在2秒左右打印出来，testonload会在3秒左右打印出来，由此可知DOMContentLoaded是js和css文件的加载后触发，onload是整个页面所有资源加载完后触发（比如图片等）。 实验五： script async 属性index.html 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('testDOMContentLoaded') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; document.addEventListener('DOMContentLoaded', function () &#123; console.timeEnd('testDOMContentLoaded') &#125;, false) &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; setTimeout(function() &#123; const el = document.getElementById('app') console.log(el) &#125;, 0) &lt;/script&gt; &lt;script async type=\"text/javascript\" src=\"/js1.js\"&gt;&lt;/script&gt; &lt;script async type=\"text/javascript\" src=\"/js2.js\"&gt;&lt;/script&gt; &lt;script async type=\"text/javascript\" src=\"/js3.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3个js文件都加上”async”,会发现输出顺序是 testDOMContentLoaded 会立即打印出来 app元素对象 js2.js loaded js1.js loaded js3.js loaded 之后我们将js1.js上的”async”移除，会发现输出顺序是 el 为 null js1.js loaded testDOMContentLoaded 1秒左右时间 js2.js loaded js3.js loaded 之后我们将js3.js上的”async”移除，会发现输出顺序是 el 为 null js1.js loaded js2.js loaded js3.js loaded testDOMContentLoaded 3秒左右时间 可见async会打乱js的执行顺序，有async的js文件哪个先加载完哪个先执行，DOMContentLoaded的触发时间不在和async有关系，不会影响页面的渲染和解析 实验六： script defer 属性index.html 1234567891011121314151617181920212223242526&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('testDOMContentLoaded') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; document.addEventListener('DOMContentLoaded', function () &#123; console.timeEnd('testDOMContentLoaded') &#125;, false) &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; setTimeout(function() &#123; const el = document.getElementById('app') console.log(el) &#125;, 0) &lt;/script&gt; &lt;script defer type=\"text/javascript\" src=\"/js1.js\"&gt;&lt;/script&gt; &lt;script defer type=\"text/javascript\" src=\"/js2.js\"&gt;&lt;/script&gt; &lt;script defer type=\"text/javascript\" src=\"/js3.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3个js文件都加上”defer”,会发现输出顺序是 app元素对象 js1.js loaded js2.js loaded js3.js loaded testDOMContentLoaded 3秒左右时间 这和没有加defer和async时一样 之后我们将js1.js上的”defer”移除，会发现输出顺序是 el 为 null js1.js loaded js2.js loaded js3.js loaded testDOMContentLoaded 3秒左右时间 这和没有加defer和async时一样 之后我们将js3.js上的”defer”移除，会发现输出顺序是 js1.js loaded js3.js loaded js2.js loaded testDOMContentLoaded 3秒左右时间 可见defer会打乱js的执行顺序，有defer的js文件会晚于没有的，但是它们（含有defer）依旧保持从上而下依次执行，DOMContentLoaded的触发时间晚于defer，不会影响页面的渲染和解析 实验七： script defer &amp; async 都加上 属性index.html 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('testDOMContentLoaded') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; document.addEventListener('DOMContentLoaded', function () &#123; console.timeEnd('testDOMContentLoaded') &#125;, false) &lt;/script&gt; &lt;script async defer type=\"text/javascript\" src=\"/js1.js\"&gt;&lt;/script&gt; &lt;script async defer type=\"text/javascript\" src=\"/js2.js\"&gt;&lt;/script&gt; &lt;script async defer type=\"text/javascript\" src=\"/js3.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3个js文件都加上”async”,会发现输出顺序是 testDOMContentLoaded 会立即打印出来 js2.js loaded js1.js loaded js3.js loaded async优先级比defer高 实验八： 动态创建scriptindex.html 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('testDOMContentLoaded') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; document.addEventListener('DOMContentLoaded', function () &#123; console.timeEnd('testDOMContentLoaded') &#125;, false) setTimeout(function () &#123; var appEl = document.getElementById('app') console.log(appEl) &#125;, 0) &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; var head = document.getElementsByTagName('head')[0] for (var i = 0; i &lt; 3; i++) &#123; var script = document.createElement('script') script.type = 'text/javascript' script.src = 'js' + (i + 1) + '.js' head.appendChild(script) &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; testDOMContentLoaded 会立即打印出来 appEl 对象 js2.js loaded js1.js loaded js3.js loaded 如果我们动态创建js1.js和js2.js，将js3.js依旧按照常规写法写在页面中的话 index.html1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; console.time('testDOMContentLoaded') &lt;/script&gt; &lt;script type=\"text/javascript\"&gt; document.addEventListener('DOMContentLoaded', function () &#123; console.timeEnd('testDOMContentLoaded') &#125;, false) setTimeout(function () &#123; var appEl = document.getElementById('app') console.log(appEl) &#125;, 0) &lt;/script&gt; &lt;script type=\"text/javascript\" src=\"js3.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; var head = document.getElementsByTagName('head')[0] for (var i = 0; i &lt; 2; i++) &#123; var script = document.createElement('script') script.type = 'text/javascript' script.src = 'js' + (i + 1) + '.js' head.appendChild(script) &#125; &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"app\"&gt;hello world&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; appEl 为 null 立即打印出来 js3.js loaded testDOMContentLoaded 3秒左右会立即打印出来 js2.js loaded js1.js loaded 可见动态创建script基本是同时加载，哪个先加载完哪个先执行，但是他们都晚于DOMContentLoaded事件 总结CSS加载会阻塞DOM渲染和JS执行，但是不影响页DOM解析；JS加载会阻塞DOM解析和渲染，给script标签加上defer &amp; async属性将不再影响DOM解析和渲染，async 是哪个先返回先执行按个，defer会晚于常规标签同时按照含有defer属性的script加载的顺序执行","link":"/2018/09/24/js-css-image-loading/"},{"title":"Node.js 监控中心架构迭代","text":"之前写了一篇收集 Node.js 应用的内存堆栈快照和 CPU 火焰图文章，其中的架构非常粗糙，但是初步算是满足了现在的监控需求。不过随着业务的增长，单台TCP Server可定无法满足高可用的需求，一旦出现问题那就没办法持续使用了，所以需要一个重新设计和改造。 大致流程介绍： 一个 Docker 中，可能运行多个 Node.js 进程，比如 Egg.js 框架，另外Helper Process是用来做火焰图采集的，前面的文章提到过，目前它的功能相对单一应该被优化。 所有的 Node.js 进程都会被看做事一个Client通过 TCP 长连接连入Server，他们做双向通信，Client 将心跳和监控数据（CPU、内存、EventLoop、GC 等）源源不断送入 Server 中，Server 将对用的数据存入到 ES 中。 用户通过Admin Web可以查看每个应用的基础数据图表，发送生成内存堆栈信息和 CPU 火焰图的信息给指定的 Client，Client 生成文件后上传到FS（文件系统），之后 Admin Web 去 FS 上抓取该文件。 Q:为什么是这样一个粗糙的设计？ 以快速上线去生产验证可用性为目标之一，尽量减少对其它系统的依赖，依赖ES是为了存数据、FS是为了存文件，过多的依赖对于部署上线还是测试链路都是增加成本，在人力有限的情况下拖的越久越容易杀死项目。 Q:为什么用长链接而不是短链接？ 长链接的好处在简单模型下有个最大的好处就是我不需要去维护客户端是否存活，因为一旦客户端挂了，那么它就会自动断开，既能发送监控警报，又不需要做相关的治理工作，治理工作又是一个细活。 另外客户端没有将数据集中定时批量发送，而是每次取到相关数据就发送给 Server。为了减少开销就用了长链接，自定义的协议传输效率也高。 在开发过程中，长链接的开发模型比短连接复杂很多，不容易维护。 Q:目前遇到的问题和思考 单机 Server 一旦挂了就没办法继续监控，导致的风险极大，需要做集群，但是长链接并不适合做扩展，所以必须长改短。 如果 Server 是集群，那势必需要 Client 去找到它，那么将引入服务注册和发现功能，比如 Eureka、Consul 等，将 Client、Server 和 Admin Web 连入。 有了 Eureka、Consul 之类中间件，其实 Admin Web 可以直接通过它找到 Client，不过为了功能单一性，还是让 Server 转发用户命令。 之前的 Helper Process 是在做火焰图时候临时加入，所有的Worker Process都是平等的 Client，在启动它的时候存在竞争问题，哪里一个 Client 去启动它呢？可以做一个类似 Egg.js 的启动命令，有 Master 进程、数个 Worker 进程已经一个 Helper Process。当然在 Egg.js 框架里，完全可以用 Agent 进程代替它，写个相关插件即可。 如果所有的 Client 和 Helper Process 都在 Master 下，那么我们可以通过 Helper Process 代理将所有的 Client 基础数据批量上传到 Server，通过父进程 Master 做转发，这样也减轻了不断传数据的性能瓶颈；另外所有的 Client 注册到注册中心也不合适，也可以通过 Helper Process 代理，这样每个 Docker 就一个服务注册了。 生成文件的过程是漫长的，不可能让短链接一直等，所以需要一个消息列队去通知 Admin Web，XXXX Client 的 XXXX 文件已经好了，让它去 FS 上拉取，需要引入 RMQ 等。 为 Admin Web 可以方便获取 Client 列表，可以将注册中心里的服务信息格式处理后存在 Redis 中，这样就引入了 Redis，如果不平凡刷新这个列表可以每次读取注册中心里的数据做格式处理。 综上思考，Server 依旧做信息的存储和命令的转发工作，Admin Web 依旧是操作命令的入口，而整个 Client 端偏向 Egg.js 的风格。渐渐的整个监控中心就变得像一个微服务集群那样存在和运行，不同阶段有不同阶段的任务目标，讲不定之后会有新的挑战需要迭代。","link":"/2020/04/03/monitor-hub/"},{"title":"Node.js服务支持多SSR版本（适合测试环境）","text":"背景通常，系统环境分为生产、测试和开发等多套，测试又可能因为验证不同的业务版本、BUG 部署 N 套， 意味着每套环境都会有一整套系统，从入口网关到大量的微服务节点，还有数据库等等。人力上需要有人去维护它们，无论是用于测试数还是系统的运维工作，每多一套系统都需要额外部署和购买大量资源，其中很多服务节点的版本是相同的，这都大大增加了成本。 为了解决这样的问题，我们可以通过网关路由的方式，比如测试环境，所有的应用都部署在一套环境中，通过 HTTP Header 信息将不同的应用通过路由串联起来，大概如下： Server A V1 -&gt; Server B V1 Server A V2 -&gt; Server B 其它版本 前端资源怎么区分多版本这里的 SSR 服务，基本是移动端的 hybrid 应用，所以在 Native 打开它时可以在 HTTP Header 注入版本信息，如果 PC 端，可以通过其它方式告诉服务器需要路由的版本，比如 URL Query 或 Cookie 之类 前置一个网关应用，在收到版本信息后，路由到 SSR 服务 优点： 无需改变当前的 SSR 服务 缺点： 作为 SSR 服务，其本身已经是一个网关，再前置一个网关有些奇怪 每部署一个 SSR 服务节点，可能就需要更新前置网关的配置，需要 2 步操作 需要多个 Docker 部署不同版本的 SSR 服务 改造 SSR 服务，收到 HTTP Header 版本信息后，在内部做版本的路由 优点： 一个 SSR 应用，就一个 Docker 只要告诉一个应用（SSR）当前有哪些是需要使用的版本即可 缺点： 市面上大部分的 SSR 框架都是对应一个 SSR 版本的，不存在多版本并行，需要一定的开发和维护 综合考虑，既然是为了节省整体成本，那就彻底点，选择了第二个方案，一劳永逸。 改造 SSR 服务CI\\CD 阶段打包客户端和服务器资源，上传到静态服务器上，其中包含重要的 client-manifest.json 和 server-manifest.json，两者记录的是资源的名称和其对应的资源访问路径，client-manifest.json 用于在服务渲染时候根据资源名插入指定的访问路径，server-manifest.json 用于将资源从静态服务器下载到 Node.js 服务器上，用于 SSR 用。 启动和运行阶段 访问配置中心，找到该应用的部署版本，比如 [‘v1,’v2’] 与本地版本做 diff 算法，算出新增和遗弃的版本 拉去新版本的 SSR 文件到本地磁盘 路由解析，因为内部的 SSR 技术被广泛应用，为了不改动代码，通过@babel/parser 和 @babel/traverse 这两个类库，先将代码转成 AST，再解析出路由信息 移除本地遗弃的 SSR 文件 将新的路由信息更新到路由表中 定时执行上述步骤 我们用的是 Egg.js，所以上述步骤在 Agent 中完成，再广播给所有 Worker 进程。另外，为了更好的迭代和任务划分，使用PlugBoard插件化所有步骤。 客户端发起访问，找到对应的路由版本（如果没有走默认路由），路由请求，有缓存直接输出，没有就走 SSR 流程，查找该版本的 client-manifest.json，找到对应的浏览器访问路径，返回给客户端。 至此，整个方案的流程完毕。项目上线后，可以通过关闭多版本共存的参数，按照市面上的常规流程运行应用。如果小团队的运维体系薄弱（没有 K8S 之类运维系统），也能用该套方案实现一定的蓝绿发布等。","link":"/2020/06/29/node-gateway-ssr-multi-version/"},{"title":"Istio简单概念","text":"文章中主要是一些概念，简单记录这段时间对 Istio 的学习。 对于全栈来说，学习 Istio 还是很有必要的，在此过程中还要学习 K8s、Docker 等基本的运维知识，那么在设计 BFF 层时候也会考虑到部署、扩容、金丝雀发布等问题，提升程序的健壮性。 JavaScript 全栈在 JavaScript 流行的今天，各种框架层出不穷，无论是学习前端的 3 架马车（React\\Vue\\Angular）、还是运用后端的 Node.js 框架（Express\\Koa\\Egg.js）等，最后你都会前后端通吃，它们被 JavaScript 这门语言串联在了一起，尤其是当你去翻阅大量前端使用的 CLI 工具源码的时候，几乎都有 Express 的影子，所以在 JavaScript 技术栈里，前后端（这里的后端不是指复杂的后端架构和设计）本身并不分家。当然复杂的后端或前端工作并不适合全栈工程师去做，那也是后话了。 BFF 层这些年来提出了 BFF 层的概念，根据业务的不同，不同公司有自己的设计和实现，比如将纯前端从 Nginx 移到了 Node.js Server 运行环境、服务端渲染（SSR）、生成或者拼接业务数据返回给前端使用（Node.js 微服务、GraphQL 等）… Node.js 微服务自己也做过很长一段时间的全栈，用 Node.js 开发后端业务，把数据吐给前端，不需要等着后端同事返回数据或者来回沟通的烦恼。现在做后端必定会遇到微服务的概念，不同的微服务有自己的 SDK 等工具帮助完成相关的注册发现，大多数情况下它们对 Java 的支持度最好，Node.js 有时候并不友善，要完善你不得不去写一些代码，比如熔断、报警等等，也是带来大量的开发测试成本。如果不幸公司内部 Java 组选择了不支持 Node.js 的架构，那么简直是灾难。 微服务的 SDK 基本上和网络通讯相关，下文的网络化可以解决这个问题。 部署手动拷贝代码到服务器上 》 Docker 化 》 K8s 如果没有 K8s，只是 Docker 的话，部署过程还是很僵硬的。有了 K8s： 自动化的容器部署 按需扩展、收缩和替换 Docker 之间的负载均衡 轻松升级版本和一键回滚 认证 服务的发现 基础的服务监控和监控检查 … K8s 可以相对轻松地管理成千上万的微服务，但是正如前面提到，因为微服务的语言不通，导致不通微服务在网络层面的功能完整性是不同的（SDK 的支持度不同），产生木桶效应。为了避免这个效应要么增加人员投入到不完善的 SDK 开发当中保持其迭代和稳定，要么聚集大量支持度较高的 SDK 开发者去完成业务工作。其实这个都是在浪费人力资源。 网格化网格化增加了服务之间通信的便捷性，解决了微服务不同语言 SDK 的差异问题，每个微服务只要聚焦自身的业务而不再需要关心服务之间的熔断、报警等问题。 Istio 构建在 K8s 之上，是网格化概念的一个实现，我就以它为例。 服务 A 和服务 B 并不直接通信，而是通过代理的方式，这个代理基本上支持 HTTP/1.1、HTTP/2、gRPC 或 TCP 等协议。 Envoy在 Istio 中默认使用Envoy作为这个代理的实现，我们称之为 Sidecar，把微服务网络通信的 SDK 抽取出来，统一交给这个 Sidecar 管理控制。 主要的功能： HTTP 7 层路由 支持多种通信协议 服务发现和动态配置 健康检查 高级负载均衡 将流量行为和数据提取，转发给 Mixer 组件 原理，K8s 环境中，同一个 Pod 内的不同容器间共享网络栈，使得 Sidecar 可以接管进出这个容器的网络流量。 Pilot配置和管理 Envoy 代理，比如流量规则、超时、熔断等，将这些信息通过通过 API 转我 Envoy 理解的格式，并广播给它们。 MixerEnvoy 通信时候，都会向 Mixer 发出预检请求，验证行为的有效性、上报数据等，为了提高性能可以使用缓存和异步提交数据。 主要功能： 策略：Istio 依仗该功能实现限流、黑白名单等功能 遥测：Istio 通过它收集所有的流量数据 Citadel身份和证书管理 GalleyGalley 是 Istio 的配置验证、提取、处理和分发组件。 实例官方 Bookinfo 应用，它由 Python、Java、Ruby、Node.js，4 种语言框架组成。实例中实现了多版本切换、金丝雀发布等等。各个模块只要专注在自己的业务领域，不需要关心网络控制。 网格化逐渐成为未来趋势，很多大厂在对内部系统做大量改造和升级，作为全栈工程师和架构师来说也需要紧跟时代的步伐。","link":"/2020/06/28/nodejs-istio-k8s-docker/"},{"title":"简单梳理Node.js创建子进程的方法（下）—— cluster","text":"前文简单梳理了Node.js使用child_process模块创建子进程的4种方法，exec、execFile、fork和spawn。接下来我们看看cluster模块如何创建子进程，后续更多内容会介绍cluster.fork启动Net Server时候为何不会因为共同监听同一个端口而不报错。 cluster fork: 衍生出一个新的工作进程，这只能通过主进程调用。 翻翻源码看看他们怎么实现的 123456789101112131415// libuv#define UV_VERSION_MAJOR 1#define UV_VERSION_MINOR 33#define UV_VERSION_PATCH 1// V8#define V8_MAJOR_VERSION 7#define V8_MINOR_VERSION 8#define V8_BUILD_NUMBER 279#define V8_PATCH_LEVEL 17// Node.js#define NODE_MAJOR_VERSION 14#define NODE_MINOR_VERSION 0#define NODE_PATCH_VERSION 0 cluster源码位置 12345678910lib - internal - cluster - child.js - master.js - round_robin_handle.js - shared_handle.js - utils.js - worker.js - cluster.js 官方示例 12345678910111213141516171819202122232425const cluster = require('cluster');const http = require('http');const numCPUs = require('os').cpus().length;if (cluster.isMaster) &#123; console.log(`主进程 $&#123;process.pid&#125; 正在运行`); // 衍生工作进程。 for (let i = 0; i &lt; numCPUs; i++) &#123; cluster.fork(); &#125; cluster.on('exit', (worker, code, signal) =&gt; &#123; console.log(`工作进程 $&#123;worker.process.pid&#125; 已退出`); &#125;);&#125; else &#123; // 工作进程可以共享任何 TCP 连接。 // 在本例子中，共享的是 HTTP 服务器。 http.createServer((req, res) =&gt; &#123; res.writeHead(200); res.end('你好世界\\n'); &#125;).listen(8000); console.log(`工作进程 $&#123;process.pid&#125; 已启动`);&#125; Q:cluster.isMaster模块如何区分是主进程还是子进程的？123// lib/cluster.jsconst childOrMaster = 'NODE_UNIQUE_ID' in process.env ? 'child' : 'master';module.exports = require(`internal/cluster/$&#123;childOrMaster&#125;`); lib/cluster.js是整个cluster的入口，根据环境变量中是否有NODE_UNIQUE_ID来区分主或子进程。 主进程通过cluster.fork创建子进程的时候，会将NODE_UNIQUE_ID传入子进程的环境变量中，最后通过child_process.fork去创建新的子进程。 1234567891011121314// lib/internal/cluster/master.js// ...cluster.isMaster = true;// ...// fork的代码下文还会提到const workerEnv = &#123; ...process.env, ...env, NODE_UNIQUE_ID: `$&#123;id&#125;` &#125;;return fork(cluster.settings.exec, cluster.settings.args, &#123; // ... env: workerEnv,&#125;);// lib/internal/cluster/child.js// ...cluster.isMaster = false; Q:cluster.fork创建子进程过程中做了些什么？cluster.setupMaster是对整个环境参数的配置； 通过createWorkerProcess里的child_process.fork去创建子进程； 之后将其和一个Worker对象做关联，worker、其子进程和当前cluster(master)都会收到几乎相同的message、exit和disconnect事件，Worker这边不多扩展，可以查阅lib/internal/cluster/worker.js； 子进程会监听internalMessage事件，什么是internalMessage事件呢？看看下面官方的介绍。 当发送 {cmd: ‘NODE_foo’} 消息时有一种特殊情况。 cmd 属性中包含 NODE_ 前缀的消息是预留给 Node.js 内核内部使用的，将不会触发子进程的 ‘message’事件。 相反，这种消息可使用 ‘internalMessage’ 事件触发，且会被 Node.js 内部消费。 应用程序应避免使用此类消息或监听‘internalMessage’ 事件，因为它可能会被更改且不会通知。 此处internalMessage事件的回调方法是internal(worker, onmessage)，internal是lib/internal/cluster/master.js里的方法，主要作用是判断监听的消息里面是否存在需要执行的回调，如果没有就会执行入参回调，这里指的是onmessage； onmessage里面有很多if-else语句，主要是根据cluster.child传送进来的消息类型(act)做出不同的处理，这里列出了一个queryServer（因为后面会介绍Net Server里多个子进程如何监听同一个端口的）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// lib/internal/cluster/master.jscluster.fork = function (env) &#123; cluster.setupMaster(); const id = ++ids; // 创建子进程 const workerProcess = createWorkerProcess(id, env); // const worker = new Worker(&#123; id: id, process: workerProcess, // 新建的子进程 &#125;); worker.on(\"message\", function (message, handle) &#123; cluster.emit(\"message\", this, message, handle); &#125;); worker.process.once(\"exit\", (exitCode, signalCode) =&gt; &#123; // ... worker.state = \"dead\"; worker.emit(\"exit\", exitCode, signalCode); cluster.emit(\"exit\", worker, exitCode, signalCode); &#125;); worker.process.once(\"disconnect\", () =&gt; &#123; // ... worker.state = \"disconnected\"; worker.emit(\"disconnect\"); cluster.emit(\"disconnect\", worker); &#125;); worker.process.on(\"internalMessage\", internal(worker, onmessage)); // 触发 fork 事件 process.nextTick(emitForkNT, worker); cluster.workers[worker.id] = worker; return worker;&#125;;function createWorkerProcess(id, env) &#123; const workerEnv = &#123; ...process.env, ...env, NODE_UNIQUE_ID: `$&#123;id&#125;` &#125;; // ... 对一些参数的组合和设定 // 调用child_process的fork方法创建子进程 return fork(cluster.settings.exec, cluster.settings.args, &#123; cwd: cluster.settings.cwd, env: workerEnv, silent: cluster.settings.silent, windowsHide: cluster.settings.windowsHide, execArgv: execArgv, stdio: cluster.settings.stdio, gid: cluster.settings.gid, uid: cluster.settings.uid, &#125;);&#125;function onmessage(message, handle) &#123; const worker = this; // ... if message.act 类型很多 这里主要讲 queryServer if (message.act === \"queryServer\") queryServer(worker, message);&#125; 123456789101112131415// lib/internal/cluster/utils.js// 在cluster的chilid和master里的send都会调用sendHelperlet seq = 0;function sendHelper(proc, message, handle, cb) &#123; if (!proc.connected) return false; // NODE_* 开头的命令触发 internalMessage message = &#123; cmd: \"NODE_CLUSTER\", ...message, seq &#125;; if (typeof cb === \"function\") callbacks.set(seq, cb); // 缓存回调 seq += 1; // cluster/child.js handle =&gt; null // cluster/master.js handle =&gt; null return proc.send(message, handle);&#125; 以上就是cluster.fork的大致过程，引入一个Worker和internalMessage概念，之后会用得到。cluster的child和master之间传输信息，都是通过sendHelper方法。 Q:cluster.fork创建的子进程如何共同监听TCP端口？解答这个问题，主要是看net模块如何创建Server的，还有就是cluster中child和master如何通信的。 官方示例虽然用的是http创建的服务，但它底层是继承的net模块，为了方便梳理，我们从net.createServer入手一步步查看源码，主要的逻辑从listen开始。 Child部分:cluster.child里创建一个TCP服务，参数port是8000，host没有传参； 调用listenInCluster方法，一看这名字就知道和cluster有关； listen是在子进程里触发的，它会通过cluster._getServer拼出一个act为serverQuery的消息发送给cluster.master； Master部分:前文提到，master.onmessage方法会根据消息的act不同而做出不同的处理，此处正是serverQuery； 进入queryServer方法，默认使用RoundRobinHandle循环分配任务； 在RoundRobinHandle构造函数中，会调用net.createServer创建一个Server，由于是在cluster.master里调用的，所以会在listenInCluster里调用server._listen2，会new 出 TCP（src/tcp_wrap.cc）作为句柄，并将其赋给server._handle，至此cluster.master已经拥有了处理TCP请求的能力，不过master有该能力是不行的，还需要让child拥有才行； RoundRobinHandle中一旦server触发了listening事件后，它会接管server._handle，用distribute重置其onconnection方法； distribute的作用就是转发新的请求TCP给cluster.child，从free列队中取出一个之前add进来的worker（这个worker和cluster.child有关联关系），发送一个act为newconn的消息让其处理这个TCP； 回到Child部分:cluster.child的onconnection收到act为newconn的请求后，会找到之前的创建的server，然后调用其onconnection（child里的该方法没有被重置）方法，然后封装出一个Socket对象，触发onnection事件； 到此，后面的就是普通业务逻辑代码了。 下面贴上了部分相关代码，还是比较多的，细节部分我也加上了注释。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// lib/net.jsfunction createServer(options, connectionListener) &#123; return new Server(options, connectionListener);&#125;function Server(options, connectionListener) &#123; // ... 大量内置属性和参数的初始化&#125;Server.prototype.listen = function (...args) &#123; // ... // 传了port参数（8000），没有host var backlog; if (typeof options.port === \"number\" || typeof options.port === \"string\") &#123; backlog = options.backlog || backlogFromArgs; if (options.host) &#123; // ... &#125; else &#123; // listenInCluster( this, null, options.port | 0, 4, backlog, undefined, options.exclusive ); &#125; return this; &#125; // ...&#125;;function listenInCluster( server, address, port, addressType, backlog, fd, exclusive, flags) &#123; exclusive = !!exclusive; if (cluster === undefined) cluster = require(\"cluster\"); if (cluster.isMaster || exclusive) &#123; server._listen2(address, port, addressType, backlog, fd, flags); return; &#125; const serverQuery = &#123; address: address, port: port, addressType: addressType, fd: fd, flags, &#125;; cluster._getServer(server, serverQuery, listenOnMasterHandle); function listenOnMasterHandle(err, handle) &#123; // ... server._handle = handle; server._listen2(address, port, addressType, backlog, fd, flags); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081// lib/internal/cluster/child.jscluster._getServer = function (obj, options, cb) &#123; let address = options.address; // ... // 当前创建的server信息是否之前已经在cluster.child里查询过 // 有的话就累加计数index值 const indexesKey = [ address, options.port, options.addressType, options.fd, ].join(\":\"); let index = indexes.get(indexesKey); if (index === undefined) index = 0; else index++; indexes.set(indexesKey, index); const message = &#123; act: \"queryServer\", index, data: null, ...options, &#125;; // ... send(message, (reply, handle) =&gt; &#123; // ... if (handle) shared(reply, handle, indexesKey, cb); // Shared listen socket. else rr(reply, indexesKey, cb); // Round-robin 返回的 handle 是null &#125;); // ...&#125;;function rr(message, indexesKey, cb) &#123; if (message.errno) return cb(message.errno, null); var key = message.key; function listen(backlog) &#123; return 0; &#125; function close() &#123; if (key === undefined) return; send(&#123; act: \"close\", key &#125;); handles.delete(key); indexes.delete(indexesKey); key = undefined; &#125; function getsockname(out) &#123; if (key) Object.assign(out, message.sockname); return 0; &#125; const handle = &#123; close, listen, ref: noop, unref: noop &#125;; if (message.sockname) &#123; handle.getsockname = getsockname; // TCP handles only. &#125; assert(handles.has(key) === false); handles.set(key, handle); cb(0, handle); // 将封装好的handle，作为listenInCluster的回调handle，赋给server._handle&#125;// Round-robin connection.function onconnection(message, handle) &#123; const key = message.key; // maseter里的key const server = handles.get(key); // 是client创建的server？ const accepted = server !== undefined; send(&#123; ack: message.seq, accepted &#125;); // 答复 master // 虽然cluster.child rr里没有为server绑定，onconnection // 但是在cb回到net.js里，后面的逻辑绑定了onconnection方法 if (accepted) server.onconnection(0, handle);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940// lib/internal/cluster/master.jsfunction queryServer(worker, message) &#123; // worker是cluster.child worker const key = `$&#123;message.address&#125;:$&#123;message.port&#125;:$&#123;message.addressType&#125;:` + `$&#123;message.fd&#125;:$&#123;message.index&#125;`; var handle = handles.get(key); if (handle === undefined) &#123; // 默认是RoundRobin，Shared模式暂不讨论有兴趣可以看源码 var constructor = RoundRobinHandle; // ... handle = new constructor( key, address, message.port, message.addressType, message.fd, message.flags ); handles.set(key, handle); &#125; // ... // 将cluster.child的worker添加到handle中 handle.add(worker, (errno, reply, handle) =&gt; &#123; const &#123; data &#125; = handles.get(key); send( worker, &#123; errno, key, ack: message.seq, data, ...reply, &#125;, handle // round_robin_handle 里返回的是一个null ); &#125;);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485// lib/internal/cluster/round_robin_handle.jsfunction RoundRobinHandle(key, address, port, addressType, fd, flags) &#123; this.key = key; this.all = new Map(); this.free = []; this.handles = []; this.handle = null; this.server = net.createServer(assert.fail); if (fd &gt;= 0) this.server.listen(&#123; fd &#125;); else if (port &gt;= 0) &#123; this.server.listen(&#123; port, host: address, // Currently, net module only supports `ipv6Only` option in `flags`. ipv6Only: Boolean(flags &amp; constants.UV_TCP_IPV6ONLY), &#125;); &#125; else this.server.listen(address); // UNIX socket path. this.server.once(\"listening\", () =&gt; &#123; this.handle = this.server._handle; // 重置onconnection方法 // distribute 做任务派发 this.handle.onconnection = (err, handle) =&gt; this.distribute(err, handle); this.server._handle = null; this.server = null; &#125;);&#125;RoundRobinHandle.prototype.add = function (worker, send) &#123; assert(this.all.has(worker.id) === false); this.all.set(worker.id, worker); const done = () =&gt; &#123; if (this.handle.getsockname) &#123; // tcp\\udp 会有getsockname const out = &#123;&#125;; this.handle.getsockname(out); // TODO(bnoordhuis) Check err. send(null, &#123; sockname: out &#125;, null); &#125; else &#123; send(null, null, null); // UNIX socket. &#125; this.handoff(worker); // In case there are connections pending. &#125;; if (this.server === null) return done(); // Still busy binding. this.server.once(\"listening\", done); this.server.once(\"error\", (err) =&gt; &#123; send(err.errno, null); &#125;);&#125;;RoundRobinHandle.prototype.distribute = function (err, handle) &#123; this.handles.push(handle); const worker = this.free.shift(); if (worker) this.handoff(worker);&#125;;RoundRobinHandle.prototype.handoff = function (worker) &#123; // worker如果不存在那就跳出 if (this.all.has(worker.id) === false) &#123; return; // Worker is closing (or has closed) the server. &#125; const handle = this.handles.shift(); // 取出第一个待处理任务 if (handle === undefined) &#123; this.free.push(worker); // 没有的话就会将worker归还到free里 return; &#125; const message = &#123; act: \"newconn\", key: this.key &#125;; sendHelper(worker.process, message, handle, (reply) =&gt; &#123; if (reply.accepted) handle.close(); else this.distribute(0, handle); // Worker is shutting down. Send to another. this.handoff(worker); &#125;);&#125;; 总结：cluster利用child_process的fork方法创建子进程，并传入新的环境变量NODE_UNIQUE_ID用于区分主子进程从而在require(‘cluster’)时候可以加载到对应的master.js和child.js文件。另外在默认的RoundRobinHandle模式下，cluster子进程之所以可以共同监听同个TCP端口，是在net模块里面做了master和child区分，child并没有真正的监听端口，而是child会去master查询该Server是否已经存在，如果没有会在RoundRobinHandle中创建中创建server，一旦有新的TCP连接进入，会转发给free里的worker（cluster.child）处理。","link":"/2020/05/03/node-js-net-cluster-fork/"},{"title":"收集Node.js应用的内存堆栈快照和CPU火焰图","text":"如果你在一家对数据安全性很高的公司工作，团队规定不允许提交数据到第三方服务上，甚至连服务器内存、CPU使用情况等监控数据都不行，那对于像Alinode这样监控和排查问题的大杀器基本都是无福享用了。大多数情况不得不面临自己开发一套类似监控体制去为生产环境保驾护航。 数据Node.js是单进程的，即使像Egg.js这样的项目存在Agent、多个Worker进程，但依旧应该把它们分为独立的进程对待，所以监控的粒度是进程级别。 基础数据 进程级别：内存、CPU、EventLoop、GC、调用该系统的时间消耗、该系统调用它人系统的时间消耗等。 系统级别：负载均衡 （os.loadavg()） 上述这些数据，有些Node.js API直接暴露出来，有些需要写C++扩展去调用底层的V8 API来获取，好在市面上存在比较多的此类类库，比如IBM appmetrics就不错，它还有很多额外的监控数据可以收集，主动定时将它们提交到Elasticsearch，在用Grafana加载出来，还是很容易做到的。 内存堆栈快照 通过多份内存堆栈快照可以帮助我们定位内存溢出的原因。 CPU火焰图 通过它可以让我们知道是代码的哪部分导致CPU非常繁忙。 上面这2个文件在系统调优和排查问题时起到至关重要的帮助，但是它们都是以文件的形式存储，又不像基础数据那么简易可以直接塞进DB里；另外获取这些资源过程是影响应用性能的，比如内存堆栈快照因为要罗列出所有的堆栈对象相互之间的关系和字节大小需要一定的计算量和时间，在此过程中系统处于无法响应的状态。为此，我们需要设计一套方法，在需要的时候去通知对应的Node.js进程，被动生成这些文件，而不是向先前那样主动收集。 命令&amp;传输我们需要通过一些方法，告诉对应的Node.js进程该干些什么事情，是生成内存堆栈快照还是CPU火焰图，又或是别的什么。需要一个发送命令的地方，也需要一种方式将命令发送给指定的Node.js进程。将一个个孤立的Node.js进程连接起来有很多方式，比如TCP，或者HTTP。 我个人比较倾向用TCP，长链、双向、数据帧也轻巧很多，等等。像下图那样将他们连起来，仅用来示意，具体细节会有些不同，简单的粗暴将单箭头表示HTTP，双箭头表示TCP双向。 命令发送：一般会有一个Web界面，通过按钮提交命令请求。 Hub：一个TCP服务，接受命令并将其转发到对应的Node.js进程上。 Node.js Process: 可能一台服务器（或者Docker等）就一个Node.js进程，如Express；也有可能如Egg.js一样是多个Node.js进程。 DFS：因为现在的服务基本都是部署在像Docker这样虚拟机上的，服务出现问题或人工原因很容易随时被系统销毁导致生产的快照或火焰图丢失，所以需要有个文件服务器持久化它们，因此一旦文件生产后就推送到文件服务器上待使用者去下载它们。 内存堆栈快照Node.js Process监听到发来的命令，通过调用heapdump很容易获得内存堆栈快照，再将文件推送到DFS上。如果想像Alinode那样自动又直接显示内存信息的话，改下devtools-frontend，将其加入到系统中即可。 CPU火焰图火焰图比其它的数据麻烦很多，官方有专门的文档说明了整个流程，总的来说需要perf和FlameGraph这两个工具，具体的方法随意Google都能查到很多，就不多叙述了，关键是如何将它融入到上述的框架中呢？ 假设和之前一样，Node.js进程用socket.on(&quot;readable&quot;,callback) 或 socket.on(&quot;data&quot;,callback)接受命令，并在callback中开启一个新的进程来执行perf等shell脚本，那么生成的火焰图不准确，为何？ Node.js是单进程，JavaScript部分是事件循环，密集计算会阻塞其它的操作，比如运行一个斐波那契数列计算。此刻，其它的异步任务就算完成也无法得到执行，比如底层IO获得了命令，但是由于JavaScript堵塞了而无法执行callback创建新进程执行shell脚本。等到斐波那契数列执行完后，callback才被执行。而我们火焰图需要排查的就是什么导致CPU一直繁忙的嗡嗡作响，而上述的问题就是密集的斐波那契数列计算，但是由于JavaScript的执行机制而有可能错过了开启perf的时机。大多数的时候，我们都是发现进程阻塞了或者CPU一直处于繁忙而去主动命令进程开启perf排查问题，所以这个方法获得的数据并不准确。 如果当前进程一直进程因为繁忙而无法执行新的JavaScript命令，那么我们是否可以通过一个简单的辅助进程来帮忙开启shell脚本呢？ 实验因为perf需要Linux环境，我们可以通过Docker在本地启动一个Node.js容器实验下，以Node.js 12为例。 下载完对应版本的Node.js Docker后，通过下面命令开启一个新的容器，必须带--privileged不然无法使用perf。 123docker run --privileged -itd node:12-buster /bin/bash // 启动docker attach xxxx // 进入 进入Docker容器后安装perf 12345apt-get updateapt-get install linux-perfperf_4.19 // 执行该命令查看是否安装成功，不同的linux内核版本对应不同的perf版本 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104// index.jsconst &#123;fork &#125; = require('child_process')fork('./helper')fibonacci(50)function fibonacci(n) &#123; if(n==0 || n == 1) return n; return fibonacci(n-1) + fibonacci(n-2);&#125;// helper.jsconst fs = require('fs');const path = require('path');const &#123; spawn, exec &#125; = require('child_process');const unzipper = require(\"unzipper\");const perfCMD = 'perf_4.19'const perfTime = 60;function execCMD(cmd, callback) &#123; return new Promise((resolve, reject) =&gt; &#123; exec(cmd, (error, stdout, stderr) =&gt; &#123; console.log('shell: ',cmd) if (error) &#123; console.error(`执行的错误: $&#123;error&#125;`); reject(error) &#125; if(callback) &#123; callback(stdout, stderr, resolve, reject); &#125; else &#123; resolve() &#125; &#125;); &#125;)&#125;class Flame &#123; constructor() &#123; this.nodes = []; this._init().catch(function(e)&#123; console.log(e) &#125;) &#125; _init () &#123; return new Promise((resolve, reject) =&gt; &#123; const zipFilePath = path.join('.', 'FlameGraph.zip') const saveDir = process.cwd(); fs.createReadStream(zipFilePath) .pipe(unzipper.Extract(&#123; path: saveDir &#125;)) .on(\"error\", reject) .on(\"finish\", () =&gt; &#123; console.log(\"zip finish\"); resolve(); &#125;); &#125;).then(() =&gt; &#123; const cmd = `chmod 700 ./FlameGraph/stackcollapse-perf.pl`; return execCMD(cmd); &#125;).then(() =&gt; &#123; const cmd = `chmod 700 ./FlameGraph/flamegraph.pl`; return execCMD(cmd); &#125;).then(() =&gt; &#123; const cmd = `ps -ef|grep node|grep -v grep|grep -v FlameGraph|awk '&#123;print $2&#125;'`; return execCMD(cmd, (stdout, stderr, resolve, reject) =&gt; &#123; this.nodes = stdout.split('\\n').filter( pid =&gt; pid &amp;&amp; pid != process.pid) resolve(); &#125;); &#125;); &#125; _chownMapFile()&#123; const cmd = `chown root /tmp/perf-$&#123;this.nodes[0]&#125;.map &amp;&amp; $&#123;perfCMD&#125; script &gt; nodestacks`; execCMD(cmd).then(() =&gt; &#123; this._genFlameGraph(); &#125;) &#125; _genFlameGraph()&#123; const cmd = `./FlameGraph/stackcollapse-perf.pl &lt; nodestacks | ./FlameGraph/flamegraph.pl --colors js &gt; node-flamegraph-$&#123;process.pid&#125;.svg` execCMD(cmd).then(() =&gt; &#123; console.log('had completed'); &#125;) &#125; record() &#123; const cmd = `$&#123;perfCMD&#125; record -F 99 -p $&#123;this.nodes[0]&#125; -g -- sleep $&#123;perfTime&#125;`; execCMD(cmd).then(() =&gt; &#123; const t = 1000 * (perfTime + 5); setTimeout(() =&gt; &#123; this._chownMapFile() &#125;, 1000 * (perfTime + 5)) &#125;) &#125;&#125;const flame = new Flame();setTimeout(() =&gt; &#123; // 模拟收到tcp命令 flame.record();&#125;, 1000 * 5) 1234567891011121314151617// package.json&#123; \"name\": \"test-perf\", \"version\": \"1.0.0\", \"description\": \"\", \"main\": \"index.js\", \"scripts\": &#123; \"dev\": \"node --perf-basic-prof index.js\", \"clear\": \"rm isolate-* &amp; rm node-flamegraph-*.svg &amp; rm -rf FlameGraph\" &#125;, \"keywords\": [], \"author\": \"\", \"license\": \"ISC\", \"dependencies\": &#123; \"unzipper\": \"^0.10.8\" &#125;&#125; index.js: 创建一个辅助进程；执行斐波那契数列计算 hepler.js: 将压缩的FlameGraph.zip解压 =&gt; 给相关文件执行权限 =&gt; 获得当前系统中除自己以外的Node.js进程号（因为可能是多个，所以是个数组，例子中假设就一个进程）=&gt; 定时模拟获得生成火焰图的命令 =&gt; 执行 perf record =&gt; 延迟5秒后生成火焰图 package.json: 启动 index.js 需要加上--perf-basic-prof命令行参数；另外还需要unzipper类包 将他们通过docker cp 从本地上传到docker中，并执行npm i安装依赖。 1npm run dev // 开始实验 随着一阵的风扇狂响（CPU密集计算）之后，火焰图也生成好了，大致如下： 之前的框架也做部分调整，每个容器需要一个Helper.js进程 总结我觉得程序员和程序猿之间的差别就在有没有一套好的监控体系和善用监控调优及排查问题的方法。如果没办法使用现成的第三方服务，往往需要自己动手去搭建，无论业务多么繁忙，唯有趁手的“兵器”才能取得真经，这是需要据理力争的东西。只有水下的冰够厚，水上的冰山才能更高。","link":"/2020/02/21/node-perf-heapdump-flame-graph/"},{"title":"2019 工作总结","text":"It was the best of times, it was the worst of times. 如果真要用一句话形容2019年工作的话，上述的双城记节选我觉得是极好。大概2018年尾的时候，公司的前端团队开始用Node.js做些后端业务等相关的工作并积累经验，与现有的Java基础架构做融合，微服务Eureka、分布式协调服务ZooKeeper、分布式配置管理平台Discon、应用监控Cat、消息列队RocketMQ、分布式署存储服务SeaweedFS、数据库MySQL等等，大量的知识扑面而来。幸好之前有.NET C# + Javascript做Web开发经历，加上一些Node.js开发经验，比如爱眠物等等，上手掌握并不难。基本上每天都有很多东西可以学，上半年忙着产出业务，也忙着封装一些基于Egg.js适合公司项目的基础代码。不过问题也是频发，上面提到的很多东西并非是Node.js生态圈大量使用的，引用一些冷门的第三个类库暴露出了EventLoop被卡住、Memory Leak的情况，下半年忙着优化和排查。 EventLoop问题我们的Node.js程序发布到测试或者生产，经常服务端出现大量TCP Close Wait的情况，从TCP的信息反馈把重点都放在了网络层面，因为大量Close Wait导致服务无法响应新的请求，以为是上下游网络的超时时间问题，但是无论如何通过Node.js的Javascript层面做实验都未能出现，后来又查系统级别的配置问题等等，都是没查出一个所以然。 我之前写的各种Node.js服务都跑的好好的，为什么现在这家公司会出现卡死的问题呢？难道把锅甩给系统环境？ 困惑和压力倍增，毕竟项目已经上生产了，金融服务出一点问题都是头大的事情。后来用alinode做监控，可惜我们的节点都在国外，而免费版本对国外节点并不友好，总是会断了监控数据。无奈只能麻烦运维同事帮忙去Docker上生成发生问题时候的火焰图，发现是Cat导致的，底层的C++代码阻碍了EventLoop的正常运行，把整个Node.js进程给卡死了。 或许你会问，为什么不早点搭建有效的监控系统去排查这些问题呢？或许就不会那么被动了！ 主要有3点： Node.js在我们上海技术团队内部算是兴起，我们希望能承接更多的业务等去做，就如同创业一样，团队自己的技术栈在公司内部使用的多了，自然有更多资源招兵买马为以后大前端、BFF层搭建做准备。可以理解为创业公司不断的做业务拉投资，我相信在很多大点的公司，很多小团队都会有这种创业的感觉 每个公司所使用的某个技术栈都有自己的定位，我们也在不同领域做尝试，有倾向业务的、有做基础设施搭建的等，也在寻找Node.js适合当前公司的定位 经验还是缺乏点，当时运维已经有了相关对Docker的系统监控，加上Cat业务监控感觉能抵挡一段时间，但是万万没想到就是缺少CPU的火焰图和内存堆栈图信息导致排查问题困难重重 Memory Leak问题前后经历了2次较大的内存泄露问题 陌生类库： 其实也是知道要谨慎选择类库的使用，但有时候又该怎么说呢… Vue SSR： 这个问题是书写Vue相关代码时候没注意导致的，其作者在Github上也留言指出了相关的解决方法 目前组内对前端或者Node.js的监控体系在逐步搭建和迭代的过程中，一个监控Hub，通过TCP通信将所有的Node.js进程与其进行长连接，实时双向传输数据，按照命令生成火焰图或者内存堆栈信息。 优化了静态资源打包和分发流程打包这个东西自然还是基于Webpack的封装，谁让人家NB呢。整体流程之前比较复杂，做了一次重CI的优化，也适合目前的小型团队使用，从中抽取了一套插件式的程序加载流程，整体思想还是抄的Egg.js，谁让人家好用好扩展呢！ 为什么不完全基于Egg.js的插件开发方式？ 团队对底层架构级的东西不能完全基于Egg.js，会有更多多元化的框架引入（看具体场景，尽量少，但万一呢），通过适配层就能让底层代码依附到不同框架上。所以我既不能依附Webpack写太多插件，也不能依附其它的Node.js应用框架，毕竟Node.js五花八门、百家争鸣，我们想办法把他们粘合在一起就好，所以需要一套自己的加载器。 从2019迈向20202019年对我而言确实又坏又好，坏的是工作上的问题一个个来，万幸的是都一个个解决和迭代中了，确实经历多了，学到的东西和成长也就多了。期望2020能把一直想做的BFF层可以慢慢做起来，另外监控等小项目能有机会开源。","link":"/2019/12/30/summary-2019/"},{"title":"一家公司的好坏，先看HR部门","text":"面对茫茫的公司，如何去判断一家公司是否靠谱呢？ 除非你关注一家公司很久了或有内线，不然光从面试过程中你真的很难说这家公司好与坏。我会比较看重HR部门，为什么？ 1.我老婆就是资深HR，深知这个部门的重要性，和被忽视性。 2.如果整个面试沟通过程中，HR部门显得很薄弱，说明该公司的组织架构不清晰，处于混沌阶段，有风险。 3.如果HR部门的素质不够，那么入职了，我也觉得后续会有麻烦，比如交金、请假等等的沟通也比较头疼。 HR需要情商智商双在线，如果一家公司拥有这样的HR说明它重视这个部门，为看似不赚钱的部门买了不少单，说明公司盈利或者业务稳定。就如，肚子饿了，只要能填饱肚子基本什么都会吃（精力只有在业务赚钱上），而真的去吃山珍海味说明有钱（会有精力把其它相关部门做好）。好的HR是对公司和员工的双保险！一些小经历 记得很多年前，手上同时拿到了盛大创新院和某社交平台的offer，该平台HR电话问我意向，我说我去创新院，她接着问我地址，我说在浦东软件园（入职的项目组正好从总部搬出来）。这HR就很嘲讽的语气说盛大在张江怎么在什么软件园呢，一顿巴拉巴拉。从此之后该社交平台我就再也不用了，确实这几年这平台不怎么样了。 前几天去某中型公司（两、三百号人左右），技术上方向不太符合，HR都没把我送出门，我从很内部的会议室自己摸索着出门，从中感受出该公司的冷漠。 有时候HR太高冷了，毕竟不是聊技术有话题，又是伤感情的薪酬环节，不知道怎么聊了，之前聊得再愉快到了这戛然而止。 电话通知我拿到offer了，但是电话那头先把我贬下，然后提出薪资结构等等。既然我不好，为什么给我offer呢？此地无银三百两的告诉我你要我去，但要压我价嘛。其实很多时候既然能谈到这部基本双方都有意向了，薪资是一方面，还有其他，避重就轻的说点吸引人的东西，不是更好，增加砝码吗？一个HR在多次和面试者沟通后，还不知道面试者除了薪资还想要什么，那么是失败的。 面试别不耐烦，多与不同人聊是好事，也是学习 聊得人越多，你越能知道公司和团队的素质，是否和自己匹配。 有些面试官做技术做产品太久了，不太和陌生人打交道，说的话、问的问题常常情商不在线，给我的感觉就是要花很长时间和团队磨合，一般自己心里会亮起警报。 总结 一场愉快的面试，是双方的尊重。面试者答应了就该准时出席，把自己所知所想告诉对方，自我的梳理和反思；面试官面了就该好好对待，可以从被面试者身上学到新的思维维度，把公司团队的产品介绍下，也算是一种推广。人与人相处，尤其是陌生人相处是需要有礼节的，你永远不知道坐在你对面的人，他背后有什么样的能量。","link":"/2018/07/20/the-quality-of-a-company-first-look-at-HR-department/"},{"title":"2019国庆一人初游舟山","text":"国庆一家三口分开旅行，各有自己的目的地，我选了舟山，离开上海不远，之前从来没有去过。一人的旅行自然应该惬意为主，打着走到哪算哪的政策主张，也给自己埋下不少的坑。 #住宿黄金周不光是游客的节日，更是商家的盛日，酒店价格也是水涨船高，本想非拖家带口的，不需要离市区多近，经济实惠就行，然后我就在Airbnb上选了一个好评不错的公寓酒店，宽敞、干净、便宜，一个房间可以放下1个主床、1个小床、1个写字台、1个休闲圆桌、3把椅子等，可惜卫生间和淋浴室不怎样，2夜才600不到，地方大约在下图红框内，舟山的汽车城边上。本想在客运中心附近，我自己坐大巴车来回方便，但是它并非是我下车的舟山普陀客运中心（下图右下角那个），打车过来100多:(，出租车司机都不忍心我的旅行泡汤劝我换个酒店（扎心）。 从酒店出来，和店员打听哪里有夜排档之类，得到的答案是各种遥远，最后选了相对近一点的定海海鲜夜排档，下图位置。一路公交晃晃悠悠，从荒郊野外到市区，感受舟山。 #吃海鲜到了地方，一条长长的海鲜排档位于2层，看不到底。可以边吃边看江海的风景，对面是若干座小岛，突然心中涌上江枫渔火对愁眠的诗句，不对情不对景色，但也是唯一的瞬间感觉了。像我这样的1人“小客户”，自然不受各个小店老板们的待见，毕竟人家做的是大桌子生意，我只能在不耐烦的目光中点了3个小菜坐在了离风景最远的角落里——一个小桌子上吃起了我海鲜大餐。 Your browser does not support the video tag. 吃完后，走了小几公里到了定海区的商业中心——凯虹广场，买了一包薯片回酒店，7点多就没公交回我住的穷乡僻廊，只能花了30多大洋打车回去，此刻心里就决定第二天要租一天车去朱家尖逛一圈。 #朱家尖大阴天 有了第一天的经历，自然知道从自己住的地方到舟山另一头的朱家尖的距离有多远，不堵车估计出租车单程200大洋。中午，从定海区一路向东，第一站是南沙海滩景区，去那边的排档吃午饭，景区一个人就没进去，毕竟人山人海。因为交通管制，导致要从大青山盘山绕路，妥妥秋名山的感觉，途中拍到了不错的海滩和被云雾缭绕的大青山，值了油钱。 吃饱开车，本想继续探索南沙海滩的，毕竟进景点海滩，一路找野生海滩过过瘾的，可惜人实在太多，各个主要路口交通管制，一不小心开错，感觉再绕进景区估计很久，就打算去另一个地方月岙大沙里沙滩（到了才发现当天没有开放，美景请自行搜索了），途中又开错了路，经过了白山景区，看到了一个画有观音像的石壁。 白山景区系观音文化苑所在地，印象普陀剧场为朱家尖最重要的景区之一，其间一座高114.9米的干丈崖上彩绘的一尊观音大立像壁画高69米，面积达2000平方米，被誉为“海上莫高窟”。 又兜兜转转的乡间小路，来到了游客相对很少的月岙大沙里沙滩旁的一条沿海小路，很宽阔的江海外也没有什么特别的感觉吧，本想当场掉头回去，可惜车技不佳，只能一直往前开到一个相对比较宽阔的道路掉头，然后，就遇到了很有感觉的地方。 从下面的地图你会发现，一个类似U形弯道的末尾，我把车调头，准备驶离的时候，眼前的小路和海景让我有种莫名的触景生情感，扭曲的小路如同自己的过往，很多事情曲折并不顺利，然而外面的世界又那么的壮阔美丽，想去了解想去看看想去感受，忍不住在车里听了几遍邓紫棋的后会无期。 在夜色慢慢落下前离开了此地回到了舟山市区。第二天还了车，坐上大巴返回了上海。 #回首玩了3天，有坑，住的远、路不熟悉等等，正是这些才促使我看到了许多没有规划的风景，人生哪有那么多规划，学会接受和享受那些原本不属于你而又是你的风景吧。","link":"/2019/10/06/travel-zhoushan/"},{"title":"出差菲律宾","text":"入职没多久，因为菲律宾项目的版本更新，和一后端、一测试，三人组队前往当地打怪升级。 副本Loading三个半小时。 住和工到达马尼拉的时候已经快晚上9点了，下飞机弄完电话卡连上网络，急忙打车去坐落在BGC的酒店——步行离公司5MIN，一个大套房3人住，好宽敞。 BGC近年来发展很快，类似上海的陆家嘴，许多大型跨国公司变迁至此（如HSBC,Google等）。 第二天，准时打开上班，新装修的办公室还是给人眼前一亮，大大小小的会议室、工作间、沙发、游戏室、健身房、食品吧台、甚至还有临时休息的房间。 吃菲律宾的餐饮感觉还是偏西餐的，油炸类的偏多，行程中吃的比较多；中餐的话基本是港式、台湾的为主，第一天晚上夜宵就是著名的鼎泰丰，味道不错。这边的水，大多是生水，国人也许喝不惯，一般在BGC一顿饭花费在1500Php左右，好一点的日料什么的那就更贵了。 因为回国航线有史诗级台风「山竹」经过，所以在菲律宾多待2天，有机会去海边逛逛随便去吃海鲜，我们去的市场感觉主要做国人生意，到处是中国人，东南亚的海鲜品种差不多，买的时候可以讨价还价。 行对于我们这些初来乍到的，还是出租车比较靠谱，机场出来还是黄色（貌似机场特有）的出租车比较靠谱，虽然贵但是没发生坐地起价或者绕路等问题，之前同事来坐白色出租车虽然起步便宜但是最后付钱的时候比我们贵很多。或者用Grab打车（类似滴滴打车），价格合理。 菲律宾特色“吉普尼”，五颜六色装饰夸张，是与黑色伦敦出租车和黄色纽约出租车齐名的交通工具，可惜没乘坐。 周边在BGC的时候感觉道路很干净，路上没有什么垃圾，甚至找个垃圾桶都很难，常常领着一袋垃圾从A处到B处目的地才有垃圾桶扔，路上没看到有人抽烟等；去之前很担心安全问题，国内常有报道，到那里后感觉很多时候没必要过于担心。 谈不上安保能力多强，平时的安检还是很多的，进大楼、酒店、商场都有安检，类似上海地铁安检吧，机器扫描或者人工打开包看，人工看的话基本都是带手套或者用一个小木棍，避免直接与物品直接接触，避免不必要的麻烦。几天下来没有谁不做检查的，不像地铁安检经常有人不愿意或者争执，其实无论在菲律宾还是国内，安检只是防君子不防小人的（和门一样），但是它也是一道保护大家的屏障，所以我们应该尊重它，而不是敌对它。 总结原本出差7天，后拜台风“山竹”所赐，多待了2天，得以有机会去海边或者更多地方逛逛。整体给我的感觉很不错，物价和上海总体差不多，若不是语言的不同，很多时候感觉自己是生活在魔都，当然天气也会常常提醒你:)。期待下次再去！","link":"/2018/09/24/traveling-to-the-philippines/"},{"title":"libuv & Node.js EventLoop （一）","text":"在网络上查询libuv和EventLoop相关信息的时候，经常看到不同的文章所表达的意思差距较多，主要原因有二吧： 它们的libuv和V8大版本不同，导致具体的实现略有差异 另外它们的代码错综复杂，又是大多数JavaScript工作者不擅长的C/C++，只是从上而下的看，或许一些细节无法完全理解或是认知的分歧 与其受他人影响，不如自己来好好梳理下。 版本 123456789101112131415// libuv#define UV_VERSION_MAJOR 1#define UV_VERSION_MINOR 33#define UV_VERSION_PATCH 1// V8#define V8_MAJOR_VERSION 7#define V8_MINOR_VERSION 8#define V8_BUILD_NUMBER 279#define V8_PATCH_LEVEL 17// Node.js#define NODE_MAJOR_VERSION 14#define NODE_MINOR_VERSION 0#define NODE_PATCH_VERSION 0 没有列出具体版本号的代码分析都是耍流氓，2010年的代码和2020年的代码可能差距甚远，“上古”分析固然在当时是对的，但是在今日也许是错误的。 libuv &amp; EventLoop文档比较 上图出自libuv的The I/O loop介绍，具体的信息可以看其文档。 上图出自Event Loop Explained，两者的各个阶段基本是对应的。哪怕是很多其它自行画的图解中，也基本差不多，但唯独pending callbacks阶段，我看到很多文章里面把它标为I/O callbacks，不知道是不是历史原因，但是就从二者的目前文档解释来看是不妥的。 Pending callbacks are called. All I/O callbacks are called right after polling for I/O, for the most part. There are cases, however, in which calling such a callback is deferred for the next loop iteration. If the previous iteration deferred any I/O callback it will be run at this point. —— libuv libuv里的pending callbacks：大多数的I/O callbacks应该在polling阶段完成，有部分会被延迟到下一个pending callbacks阶段执行。 This phase executes callbacks for some system operations such as types of TCP errors. For example if a TCP socket receives ECONNREFUSED when attempting to connect, some *nix systems want to wait to report the error. This will be queued to execute in the pending callbacks phase. —— Node.js Node.js里的pending callbacks：这个阶段会执行系统上发生的一些错误而导致的callbacks，如TCP错误。 我觉得pending callbacks比较合理，一方面如libuv所说，它是一部分延迟的I/O回调，在Node.js里面指的是一些系统上的错误（这些错误也是I/O引起的）。而大多数的I/O操作其实是在 poll阶段。 libuv的大致流程代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int uv_run(uv_loop_t* loop, uv_run_mode mode) &#123; // 默认 mode 是 UV_RUN_DEFAULT int timeout; int r; int ran_pending; // 是否还存在alive的事件 r = uv__loop_alive(loop); if (!r) uv__update_time(loop); // 存在的话更新当前的时间，可以把这个时间理解为libuv里面统一的时间，方便触发定时任务 while (r != 0 &amp;&amp; loop-&gt;stop_flag == 0) &#123; uv__update_time(loop); // 和libuv图里的 Update loop time对应 uv__run_timers(loop); // 执行 timers 阶段 ran_pending = uv__run_pending(loop); // 执行pending 阶段；返回0表示空，1表示有； uv__run_idle(loop); // idle 阶段； Node.js里面不太关心 uv__run_prepare(loop); // prepare 阶段； Node.js里面不太关心 timeout = 0; // 初始化阻塞 poll 阶段的超时时间 if ((mode == UV_RUN_ONCE &amp;&amp; !ran_pending) || mode == UV_RUN_DEFAULT) timeout = uv_backend_timeout(loop); // 算出阻塞 poll 阶段的超时时间 // 根据timers里最近的超时时间算出一个差值 diff = loop.time - min.timeout // 如果 diff &gt;= 0 , timeout = 0 // 否则 timeout = min(diff, INT_MAX) uv__io_poll(loop, timeout); // 执行 poll 阶段 uv__run_check(loop); // 执行 check 阶段 uv__run_closing_handles(loop); // 执行 close 阶段 // mode 默认 UV_RUN_DEFAULT 所以不执行下面 if (mode == UV_RUN_ONCE) &#123; uv__update_time(loop); uv__run_timers(loop); &#125; // 查看是否还有alive事件 r = uv__loop_alive(loop); if (mode == UV_RUN_ONCE || mode == UV_RUN_NOWAIT) break; &#125; /* The if statement lets gcc compile it to a conditional store. Avoids * dirtying a cache line. */ if (loop-&gt;stop_flag != 0) loop-&gt;stop_flag = 0; return r;&#125; 上述uv_run方法同样表达了之前图的循环流程，接下来我们看看各个阶段的具体执行方法。 12345678910111213141516171819void uv__run_timers(uv_loop_t* loop) &#123; struct heap_node* heap_node; // timers 里的都是按照最小堆存放的 uv_timer_t* handle; for (;;) &#123; heap_node = heap_min(timer_heap(loop)); // 从堆顶取出一个 if (heap_node == NULL) // 不存在就退出 break; handle = container_of(heap_node, uv_timer_t, heap_node); if (handle-&gt;timeout &gt; loop-&gt;time) // 触发时间没达到也退出 break; uv_timer_stop(handle); uv_timer_again(handle); handle-&gt;timer_cb(handle); // 执行回调 &#125;&#125; timers里存放的事件都是最小堆的数据结构排列的，不断的取出根节点比较当前的loop-&gt;time就能知道是执行还是退出，那么这里的handle-&gt;timer_cb是我们平时JavaScript里的setTimeout回调吗？后续解答 1234567891011121314151617181920static int uv__run_pending(uv_loop_t* loop) &#123; QUEUE* q; QUEUE pq; uv__io_t* w; if (QUEUE_EMPTY(&amp;loop-&gt;pending_queue)) return 0; QUEUE_MOVE(&amp;loop-&gt;pending_queue, &amp;pq); while (!QUEUE_EMPTY(&amp;pq)) &#123; // 双向链表，为空就跳出 q = QUEUE_HEAD(&amp;pq); QUEUE_REMOVE(q); QUEUE_INIT(q); w = QUEUE_DATA(q, uv__io_t, pending_queue); w-&gt;cb(loop, w, POLLOUT); // 执行回调 &#125; return 1;&#125; libuv里面事件很多是由双向链表构建而成，等着被一个个执行，双向链表的好处就是插入很容易。 123456789101112131415161718#define UV_LOOP_WATCHER_DEFINE(name, type) \\ void uv__run_##name(uv_loop_t* loop) &#123; \\ uv_##name##_t* h; \\ QUEUE queue; \\ QUEUE* q; \\ QUEUE_MOVE(&amp;loop-&gt;name##_handles, &amp;queue); \\ while (!QUEUE_EMPTY(&amp;queue)) &#123; \\ q = QUEUE_HEAD(&amp;queue); \\ h = QUEUE_DATA(q, uv_##name##_t, queue); \\ QUEUE_REMOVE(q); \\ QUEUE_INSERT_TAIL(&amp;loop-&gt;name##_handles, q); \\ h-&gt;name##_cb(h); \\ &#125; \\ &#125; UV_LOOP_WATCHER_DEFINE(prepare, PREPARE)UV_LOOP_WATCHER_DEFINE(check, CHECK)UV_LOOP_WATCHER_DEFINE(idle, IDLE) UV_LOOP_WATCHER_DEFINE宏直接初始化了prepare、check和idle3个阶段，都是双向链表。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// uv__io_poll 太长了，不重要的代码已经移除void uv__io_poll(uv_loop_t* loop, int timeout) &#123; // ... if (loop-&gt;nfds == 0) &#123; // 没有需要执行的 直接退出 assert(QUEUE_EMPTY(&amp;loop-&gt;watcher_queue)); return; &#125; // 将loop-&gt;watcher_queue列队里的待观察的文件描述符绑定到epoll上 while (!QUEUE_EMPTY(&amp;loop-&gt;watcher_queue)) &#123; q = QUEUE_HEAD(&amp;loop-&gt;watcher_queue); QUEUE_REMOVE(q); QUEUE_INIT(q); w = QUEUE_DATA(q, uv__io_t, watcher_queue); // ... if (w-&gt;events == 0) op = EPOLL_CTL_ADD; // 添加 else op = EPOLL_CTL_MOD; // 修改 epoll_ctl(loop-&gt;backend_fd, op, w-&gt;fd, &amp;e) // epoll_ctl 底层的系统函数，将文件描述符关联起来 w-&gt;events = w-&gt;pevents; &#125; sigmask = 0; if (loop-&gt;flags &amp; UV_LOOP_BLOCK_SIGPROF) &#123; sigemptyset(&amp;sigset); sigaddset(&amp;sigset, SIGPROF); sigmask |= 1 &lt;&lt; (SIGPROF - 1); &#125; base = loop-&gt;time; real_timeout = timeout; for (;;) &#123; nfds = epoll_wait(loop-&gt;backend_fd, events, ARRAY_SIZE(events), timeout); if (nfds == 0) &#123; // 超时，没有新的事件准备好 assert(timeout != -1); // -1 表示不会超时，而nfds为0表示超时，存在矛盾所以抛出异常 if (timeout == 0) // 退出 return; goto update_timeout; // 重新更新时间 准备下次循环 epoll_wait &#125; if (nfds == -1) &#123; // 出错 if (errno == ENOSYS) &#123; /* epoll_wait() or epoll_pwait() failed, try the other system call. */ assert(no_epoll_wait == 0 || no_epoll_pwait == 0); continue; &#125; if (errno != EINTR) abort(); if (timeout == -1) continue; if (timeout == 0) return; goto update_timeout; &#125; have_signals = 0; nevents = 0; loop-&gt;watchers[loop-&gt;nwatchers] = (void*) events; loop-&gt;watchers[loop-&gt;nwatchers + 1] = (void*) (uintptr_t) nfds; for (i = 0; i &lt; nfds; i++) &#123; pe = events + i; fd = pe-&gt;data.fd; w = loop-&gt;watchers[fd]; w-&gt;cb(loop, w, pe-&gt;events); // 这个for循环很长，这里我简化了，其实就是准备好的IO就执行回调 &#125; if (timeout == 0) return; if (timeout == -1) continue;update_timeout: assert(timeout &gt; 0); real_timeout -= (loop-&gt;time - base); if (real_timeout &lt;= 0) return; timeout = real_timeout; &#125;&#125; uv__io_poll里的timeout参数是根据timers里的最近一次定时时间计算出来的。方法内部使用了epoll，是IO多路复用的一个概念。一共有三种：select、poll和epoll。 epoll是Linux内核为处理大批量文件描述符而作了改进的poll，是Linux下多路复用IO接口select/poll的增强版本，它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。另一点原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了。epoll除了提供select/poll那种IO事件的水平触发（Level Triggered）外，还提供了边缘触发（Edge Triggered），这就使得用户空间程序有可能缓存IO状态，减少epoll_wait/epoll_pwait的调用，提高应用程序效率。 ——百度百科 我觉得libuv使用epoll主要是因为支持其自身的异步特点 epoll监控的文件描述符远远大于select/poll 在大量并发的时候epoll性能远远高于select/poll，而少量异步select/poll相对好点。Node.js利用了libuv的高并发特点。 12345678910111213static void uv__run_closing_handles(uv_loop_t* loop) &#123; uv_handle_t* p; uv_handle_t* q; p = loop-&gt;closing_handles; loop-&gt;closing_handles = NULL; while (p) &#123; q = p-&gt;next_closing; uv__finish_close(p); p = q; &#125;&#125; 一个个触发close回调 上述就是libuv各个阶段的大体流程，poll最为复杂，还有很多东西可以留着细品。 Node.js setTimeout上文中提到那么这里的handle-&gt;timer_cb是我们平时JavaScript里的setTimeout回调吗？回答：不是的 看看Node.js里面如何具体实现这个setTimemout方法的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546function setTimeout(callback, after, arg1, arg2, arg3) &#123; var args = [arg1, arg2, arg3]; // 简化了代码 const timeout = new Timeout(callback, after, args, false); active(timeout); return timeout;&#125;function Timeout(callback, after, args, isRepeat) &#123; // 省略了部分代码 after *= 1; if (!(after &gt;= 1 &amp;&amp; after &lt;= TIMEOUT_MAX)) &#123; after = 1; // 定时验证不过 就为1 &#125; this._idleTimeout = after; this._onTimeout = callback; this._timerArgs = args;&#125;function active(item) &#123; insert(item, true, getLibuvNow()); // getLibuvNow 获取 loop-&gt;time时间&#125;function insert(item, refed, start) &#123; let msecs = item._idleTimeout; if (msecs &lt; 0 || msecs === undefined) return; // Truncate so that accuracy of sub-millisecond timers is not assumed. msecs = Math.trunc(msecs); item._idleStart = start; // Use an existing list if there is one, otherwise we need to make a new one. // timerListMap 是一个键值对，key 是定时时间，value 是一个TimersList var list = timerListMap[msecs]; if (list === undefined) &#123; const expiry = start + msecs; // 过期时间 timerListMap[msecs] = list = new TimersList(expiry, msecs); // 双向链表 timerListQueue.insert(list); // timerListQueue 用数组实现的最小堆 if (nextExpiry &gt; expiry) &#123; scheduleTimer(msecs); // 如果此次定时任务的有效时间小的话，调用 V8 scheduleTimer nextExpiry = expiry; &#125; &#125; // ... 这边简略代码 L.append(list, item); // 将setTimeout创建的Timeout对象添加到list尾部&#125; 通过上述代码，我们也可以看出JavaScript层面也有一个维护timers的最小堆，并没有吧具体的某个setTimeout注册到V8里面，只是将定时时间告诉了V8scheduleTimer(msecs);，下面是V8相关代码。 123456789101112131415161718192021222324252627282930313233343536373839// timers.ccvoid ScheduleTimer(const FunctionCallbackInfo&lt;Value&gt;&amp; args) &#123; auto env = Environment::GetCurrent(args); env-&gt;ScheduleTimer(args[0]-&gt;IntegerValue(env-&gt;context()).FromJust());&#125;// env.ccvoid Environment::ScheduleTimer(int64_t duration_ms) &#123; if (started_cleanup_) return; uv_timer_start(timer_handle(), RunTimers, duration_ms, 0);&#125;void Environment::RunTimers(uv_timer_t* handle) &#123; Environment* env = Environment::from_timer_handle(handle); // timers_callback_function 从何而来呢？ Local&lt;Function&gt; cb = env-&gt;timers_callback_function(); do &#123; ret = cb-&gt;Call(env-&gt;context(), process, 1, &amp;arg); &#125; while (ret.IsEmpty() &amp;&amp; env-&gt;can_call_into_js());&#125;// uv/timer.cint uv_timer_start(uv_timer_t* handle, uv_timer_cb cb, uint64_t timeout, uint64_t repeat) &#123; // 给uv_timer_t对象初始化相关属性 // 并没有JavaScript层面的回调方法，具体的回调也只是C++的RunTimers handle-&gt;timer_cb = cb; handle-&gt;timeout = clamped_timeout; handle-&gt;repeat = repeat; handle-&gt;start_id = handle-&gt;loop-&gt;timer_counter++; // 将uv_timer_t添加到timer_heap上 heap_insert(timer_heap(handle-&gt;loop), (struct heap_node*) &amp;handle-&gt;heap_node, timer_less_than); uv__handle_start(handle); return 0;&#125; V8部分注册在timers阶段的是一个C++的回调方法，其内部是执行timers_callback_function方法，它从何来来？ 123456789// timers.ccvoid SetupTimers(const FunctionCallbackInfo&lt;Value&gt;&amp; args) &#123; CHECK(args[0]-&gt;IsFunction()); CHECK(args[1]-&gt;IsFunction()); auto env = Environment::GetCurrent(args); env-&gt;set_immediate_callback_function(args[0].As&lt;Function&gt;()); // 注册了immediate回调 env-&gt;set_timers_callback_function(args[1].As&lt;Function&gt;()); // 注册了timers回调&#125; 12345678910111213// node.jsconst &#123; setupTaskQueue, queueMicrotask&#125; = require('internal/process/task_queues');const &#123; nextTick, runNextTicks &#125; = setupTaskQueue();process.nextTick = nextTick;process._tickCallback = runNextTicks;const &#123; getTimerCallbacks &#125; = require('internal/timers');const &#123; setupTimers &#125; = internalBinding('timers'); // c++ SetupTimers 方法传到了JavaScript层const &#123; processImmediate, processTimers &#125; = getTimerCallbacks(runNextTicks);setupTimers(processImmediate, processTimers); 我们通过上述代码看到在node.js里面会将processImmediate和processTimers这两个JavaScript方法注册到对应的C++回调里，之后执行timers_callback_function其实就是执行processTimers方法。 另外，需要注意微任务相关的代码会被带到getTimerCallbacks。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980function getTimerCallbacks(runNextTicks) &#123; function processImmediate() &#123; // 之后文章在做介绍 &#125; function processTimers(now) &#123; nextExpiry = Infinity; let list; let ranAtLeastOneList = false; while (list = timerListQueue.peek()) &#123; if (list.expiry &gt; now) &#123; // 当前列表的过期时间大于now(libuv loop-&gt;time), 还没有到过期或到触发时间 nextExpiry = list.expiry; // nextExpiry 设置为 当前列表的过期时间 return refCount &gt; 0 ? nextExpiry : -nextExpiry; &#125; if (ranAtLeastOneList) runNextTicks(); // 微任务会被触发 else ranAtLeastOneList = true; listOnTimeout(list, now); &#125; return 0; &#125; function listOnTimeout(list, now) &#123; const msecs = list.msecs; debug('timeout callback %d', msecs); var diff, timer; let ranAtLeastOneTimer = false; while (timer = L.peek(list)) &#123; // 如果不是一个空的list，持续执行 // _idleStart 是插入libuv (loop-&gt;time)的时间 // now 是当前libuv 执行此次callback的时间 diff = now - timer._idleStart; // Check if this loop iteration is too early for the next timer. // This happens if there are more timers scheduled for later in the list. if (diff &lt; msecs) &#123; list.expiry = Math.max(timer._idleStart + msecs, now + 1); list.id = timerListId++; timerListQueue.percolateDown(1); debug('%d list wait because diff is %d', msecs, diff); return; &#125; if (ranAtLeastOneTimer) runNextTicks(); // 微任务会被触发 else ranAtLeastOneTimer = true; // The actual logic for when a timeout happens. L.remove(timer); const asyncId = timer[async_id_symbol]; if (!timer._onTimeout) &#123; continue; &#125; try &#123; const args = timer._timerArgs; if (args === undefined) timer._onTimeout(); // _onTimeout setTimeout 回调 else timer._onTimeout(...args); &#125; finally &#123; // ... &#125; &#125; if (list === timerListMap[msecs]) &#123; delete timerListMap[msecs]; timerListQueue.shift(); &#125; &#125; return &#123; processImmediate, processTimers &#125;;&#125; 上述代码很长，但是很容易理解，就是根据libuv的时间，将到期的定时任务一一执行了，格外需要注意的是微任务的执行runNextTicks，每次setTimeout的callback之后都会将微任务清空，而不是网上很多文章说的timer阶段之后将微任务清空，这个改动在Node.js 11版本 TimersInterval timers will be rescheduled even if previous interval threw an error. #20002nextTick queue will be run after each immediate and timer. #22842 具体的原因是希望和浏览器里的行为更为一直，下面的代码在11之前和之后的执行结果略有不同。 123456789101112131415161718192021222324252627setTimeout(() =&gt; &#123; console.log('time1'); Promise.resolve().then(() =&gt; &#123; console.log('promise1'); &#125;);&#125;);setTimeout(() =&gt; &#123; console.log('time2'); Promise.resolve().then(() =&gt; &#123; console.log('promise2'); &#125;);&#125;);/* 11之后time1promise1time2promise2*//* 11之前time1time2promise1promise2*/ 总结至此，libuv和Node.js EventLoop关于各个阶段和setTimeout的实现已经做了简单介绍。具体的还是需要看各自版本的代码而定，不能轻易去“相信”网上的介绍，比如最后一个例子就很容易在不同版本出现不同的执行结果。之后，有时间介绍 nextTick的回调实现，这个比较复杂。","link":"/2020/03/01/v8-libuv-timer-event-loop/"},{"title":"V8是如何怎么处理JavaScript的","text":"此文介绍的内容已经算是旧闻了，17年的时候就有大量的文章介绍过了，只是2020年伊始的疫情把人困在家里实在无聊，重新翻来几个视频打发下时间，以下文字算是简单梳理，更多的瑰宝需要我们自己翻阅资料研究，文章中的很多数据应该都过时了吧，仅用来参考吧。 Parer和Compiler是2个重要的过程和概念，理解它们可以帮助开发者根据业务需求写出对V8或其它JavaScript引擎更为“友善”的代码，毕竟花在这两个过程中的成本是巨大的。 Parser 解析速率大约为 1 MB / s V8的Parser分2次解析：Layze（Pre-Parsing）： 跳过还未被使用的代码 不会生成AST，会产生不带有变量引用和声明的Scopes信息 解析速度是Eage的2倍 根据JavaScript规范抛出一些特定的错误 Eage（Full-Parsing）： 解析那些被使用的代码 生成AST 构建具体的Scopes信息，变量的引用、声明等 抛出所有的语法错误 Q:为什么会有2次解析？如果都是用Full-Parsing的话，那么整个解析会非常漫长浪费时间。我们通过DevTools的coverage工具可以发现页面上大量的代码并没有被使用 Q:2次解析会有什么负面影响？如果代码已经被Pre-Parsing解析过了，当被执行的时候还是会被Full-Parser解析一次那么开销是: 0.5 * parse + 1 * parse = 1.5 parse 从某个角度来说更复杂了、开销更大了。鱼和熊掌不可兼得！ Q:什么样的代码会被 Pre-Parsing 处理，什么样的会被 Full-Parsing 处理？12345678910111213141516let a = 0; // Top-Level 顶层的代码都是 Full-Parsing// 立即执行函数表达式 IIFE = Immediately Invoked Function Expression(function eager() &#123;...&#125;)(); // 函数体是 Full-Parsing // 顶层的函数非IIFEfunction lazy() &#123;...&#125; // 函数体是 Pre-Parsinglazy(); // -&gt; Full-Parsing 开始解析和编译！ // 强制触发Full-Parsing解析!function eager2() &#123;...&#125;, function eager3() &#123;...&#125; // All eager let f1 = function lazy() &#123; ... &#125;; // 函数体是 Pre-Parsing let f2 = function lazy() &#123;...&#125;(); // 先触发了lazy 解析, 然后又eager解析 Q:如何强制Full-Parsing （eager ）？ lazy 预编译由前2位首字母决定；所以如果我们想跳过 lazy 触发 eager 编译，我们应该在前面加位操作符，例如’!|~’。 使用 optimize-js 重新编译代码，具体的性改变可以参考它Github里的测试数据 Q:什么是连续重新解析12345678910function lazy_outer() &#123; // lazy parse this function inner() &#123; function inner2() &#123; // ... &#125; &#125;&#125;lazy_outer(); // lazy parsing inner &amp; inner2inner(); // lazy parsing inner &amp; inner2 (3rd time!) 从上可知，大量的深度内嵌的代码对解析有着性能影响，每一层的深度调用都会引发新一轮的Pre-Parsing。 Q:既然Parser阶段会性能消耗很大，我们该怎么优化代码？ 尽量减少代码，可以通过DevTools的coverage工具查看当前页面代码的使用率。 V8会缓存Parser阶段的结果并保存72小时，如果bundle中间有部分代码被修改了，那么整个bundle的Parser缓存都会失效，所以把经常变动的打包在一起，非经常变动的在一起，比如公共类库和业务代码分离。 Q:如何评估当前网站代码的Parser时间呢？（包括后面将的Compiler时间）1.使用 chrome://tracing/工具，我们以爱眠物为例 2.打开tracing界面，点击左上角的Record按钮 3.在弹出的界面中选择Web developer和在Edit categories里面选择v8.runtime_stats 4.在新的Tab中输入 http://aimianwu.com ，回到tracing Tab 5.等待数据采集完成，然后”停止”记录 6.选择对应的Process和数据 7.查看V8里的Parse和Compile数据 Compiler Pipeline随着V8的迭代，整个Compiler Pipeline也在发生翻天覆地的变化。最近的一次大更新是在V8 5.9版本，用 Ignition + TurboFan 代替了从2010一直服务的Full-codegen + Crankshaft组合，当然整个过程也不是一蹴而就的，中间夹杂着特殊的版本， Ignition + TurboFan 、Full-codegen + Crankshaft它们以特殊的方式共存了一段时间，因为一开始TurboFan的性能无法满足需求，可以看这个PPT。 Q:为什么做了替换？官方介绍因为老的版本比较激进，直接将JavaScript翻译成了机器码，在执行性能上确实很快，但是带来了几个大问题 直接将JavaScript编译成机器码既费时间又费内存，几乎占用了V8约1/3的堆内存，导致实际可被使用的内存减少；另外由于复杂的设计导致Crankshaft重复编译代码，拖累性能。 Crankshaft没有友善处理 try、catch、finally 等关键词 ；维护成本高，需要为多个芯片架构提供优化代码，但性能提升不够明显；对ES新的语法特性支持不够好、也无法支持WebAssembly；在PC端老的组合感受还好，但是在移动端随着网页的不断复杂化，该组合的启动时间和性能慢慢有些力不从心了。 Q:什么样的代码对 V8 Compiler 友好？虽然JavaScript是动态语言，如橡皮泥一样随意被开发者“随意”塑造、快速开发出一个又一个应用，但是没有规矩就会带来混乱，增加编译器的优化负担，目前在V8中优化工作由TurboFan完成。Ignition会收集大量信息交给TurboFan去优化，多方面条件都满足的情况下会被优化成机器码，这个过程成为Optimize，当判断无法优化时就触发去优化——Deoptimize，这些代码逻辑又重新回到Ignition中成为字节码。 主要有以下2点视频 自然是经常被调用的代码部分 不要总是在改变对象类型（虽然JavaScript是动态的） 如果你总是在改变Objects，V8无法对它做优化。即使做了优化也会被De-optimisation，这意味着会有性能损失。 12345678function load(obj) &#123; return obj.x&#125;var obj = &#123; x: 1, y: 4&#125; 对编译器而言 obj = {} 是一种类型， obj = { x: &quot;Number&quot; } 是另一种类型，obj = { y: &quot;Number&quot; } 又是一种类型等等，也就说数据类型和字段名必须一致，如果用过静态语言比如C++、Java就很容易理解。 像下面这样的代码 1234load(&#123; x: 4, a: 7 &#125;);load(&#123; x: 4, b: 9 &#125;);load(&#123; x: 4, c: 3 &#125;);load(&#123; x: 4, d: 1 &#125;); 没办法被优化，只有将参数的入参格式一致才行，比如 1234load(&#123; x: 4, a: 7, b: undefined, c: undefined, d: undefined &#125;);load(&#123; x: 4, a: undefined, b: 9, c: undefined, d: undefined &#125;);load(&#123; x: 4, a: undefined, b: undefined, c: 3, d: undefined &#125;);load(&#123; x: 4, a: undefined, b: undefined, c: undefined, d: 1 &#125;); 是不是觉得学习TypeScript很重要了呢？ 总结V8在不断的迭代和进步，还有Script Streaming等等技术没有介绍。随便翻阅 https://v8.dev/ 就会发现数不尽的干货在里面躺着，等我们动手发掘和尝试。作为一个JavaScript工程师而言，无论是学习V8还是其它的编译引擎都能使得我们更好的写出高性能代码、优化代码、甚至在做架构的时候提供帮助。 另外，随着WebAssembly进入浏览器和Node.js，越来越多的C++等技术会被更方便的加入到JavaScript阵营当中。最近买了树莓派和Arduino，在它们身上使用JavaScript做一些功能多多少少离不开C/C++，感觉到了需要系统化学习C/C++的时候了。 主要参考：Parsing JavaScript - better lazy than eager JavaScript engines - how do they even? JavaScript Start-up Performance V8: Hooking up the Ignition to the Turbofan","link":"/2020/02/08/v8-parser-compiler-javascript/"},{"title":"Vue Component 继承与复用","text":"在做Web前端开发的时候会有大量的页面复用的地方，从UI布局到JS的逻辑。早年做后端开发的时候，我们通常可以通过面向对象的编程法式，使用抽象类、接口等等，那么现在前端是否也可以如此呢？ 答案自然是肯定的，所以我们找工作面试的时候常被问及关于JS继承的问题，随之ES6出现了期盼已久的Class，一切都在往更为成熟的方向发展。接下我们以Vue为例，看看怎么去做继承这件事情。 需求描述简单实现2个列表页面，一个是管理员列表、一个用户列表 从上可以看出2个页面整体页面结构相同，在具体细节上会有些少于不同，第一反应就是使用前文提到的继承之类的东西去实现它。 环境 Vue 版本 2.5 Element-UI （仅仅使得Demo看上去不那么丑） 测试代码 步骤通过vue cli工具创建项目1vue create vue-component-extedns 此刻我们可以拥有一个Vue的默认开发目录结构和代码，我开始对其进行修改 引入Element-UI 123456789101112// main.js import Vue from 'vue'import ElementUI from 'element-ui'import 'element-ui/lib/theme-chalk/index.css'import App from './App.vue'Vue.config.productionTip = falseVue.use(ElementUI)new Vue(&#123; render: h =&gt; h(App)&#125;).$mount('#app') 在components目录下分别创建ListPageAbstract.vue、AdminPageAbstract.vue、ButtonClick.vue和Title.vue 下面代码很多可以先跳过，看后续的介绍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170// ButtonClick.vue&lt;template&gt;&lt;div&gt; &lt;el-button size=\"small\" plain type=\"primary\" @click.stop=\"click\"&gt; &#123;&#123; label &#125;&#125; &lt;/el-button&gt;&lt;/div&gt;&lt;/template&gt;&lt;script type=\"text/javascript\"&gt; export default &#123; props: ['click', 'label', 'opt'], mounted () &#123; console.log('ButtonClick mounted') &#125; &#125;&lt;/script&gt;// Title.vue&lt;template&gt; &lt;div class=\"title\"&gt;&#123;&#123; title &#125;&#125;&lt;/div&gt;&lt;/template&gt;&lt;script type=\"text/javascript\"&gt;export default &#123; props: ['title']&#125;&lt;/script&gt;// ListPageAbstract.vue&lt;template&gt; &lt;div&gt; &lt;Title :title=\"title\" /&gt; &lt;div&gt; &lt;el-form v-if=\"config &amp;&amp; config.filter\" ref='form' :inline=\"true\" :model=\"filterForm\"&gt; &lt;el-form-item v-if=\"config.filter.conditions.indexOf('name') &gt;= 0\" label=\"名字\" prop=\"name\"&gt; &lt;el-input v-model=\"filterForm.name\"&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item v-if=\"config.filter.conditions.indexOf('phone') &gt;= 0\" label=\"手机\" prop=\"date\"&gt; &lt;el-input v-model=\"filterForm.date\"&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item v-if=\"config.filter.conditions.indexOf('date') &gt;= 0\" label=\"时间\" prop=\"date\"&gt; &lt;el-input v-model=\"filterForm.date\"&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;el-form-item v-if=\"config.filter.conditions.indexOf('status') &gt;= 0\" label=\"状态\" prop=\"status\"&gt; &lt;el-select v-model=\"filterForm.status\" placeholder=\"请选择\"&gt; &lt;el-option v-for=\"option in statusOptions\" :label=\"option.text\" :value=\"option.value\" :key=\"option.value\"&gt;&lt;/el-option&gt; &lt;/el-select&gt; &lt;/el-form-item&gt; &lt;!-- &lt;div&gt; &lt;slot name=\"filter-slot\"&gt;&lt;/slot&gt; &lt;/div&gt; --&gt; &lt;el-form-item&gt; &lt;el-button type=\"primary\" @click.stop=\"config.filter.action\"&gt;提交&lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;/div&gt; &lt;el-table v-if=\"config\" :data=\"list\" &gt; &lt;el-table-column v-for=\"(item, index) in config.table.column\" :key=\"index\" :prop=\"item.key\" :label=\"item.label\"&gt; &lt;/el-table-column&gt; &lt;el-table-column v-if=\"config.table.action\" :label=\"config.table.action.headerLabel\"&gt; &lt;template slot-scope=\"scope\"&gt; &lt;Button :click=\"config.table.action.click.bind(null, scope.row)\" :label=\"config.table.action.label\" :opt=\"config.table.action\" /&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;/div&gt;&lt;/template&gt;&lt;script type=\"text/javascript\"&gt;import Button from './ButtonClick.vue'import Title from './Title.vue'export default &#123; components: &#123; Button, Title &#125;, data: function () &#123; return &#123; filterForm: &#123; &#125;, statusOptions: [], list: [], title: null, config: null &#125; &#125;, mounted: function () &#123; this.config = this.createConfig() this.fetchOptions() this.fetchData() &#125;, methods: &#123; createConfig () &#123; let config = &#123;&#125; config.filter = &#123; conditions: [ 'name', 'status' ], action: () =&gt; &#123; this.fetchData(this.filterForm) &#125; &#125; config.table = &#123; column: [ &#123; key: 'name', label: '用户名' &#125;, &#123; key: 'phone', label: '手机号码' &#125;, &#123; key: 'status', label: '状态' &#125; ], action: &#123; headerLabel: '操作', label: '修改', click: this.editRow &#125; &#125; return config &#125;, fetchOptions () &#123; this.statusOptions = [ &#123; value: 1, text: 'status1' &#125;, &#123; value: 2, text: 'status2' &#125; ] &#125;, async fetchData () &#123; &#125;, editRow (item) &#123; console.log(`update data =&gt; $&#123;item.name&#125;`) &#125; &#125;&#125;&lt;/script&gt;&lt;style type=\"text/css\"&gt;.title &#123; color: red; margin-bottom: 20px;&#125;&lt;/style&gt;// AdminListPage.vue&lt;script type=\"text/javascript\"&gt;import ListPageAbstract from './ListPageAbstract'// 模拟ajax请求// 仅做了名字的模糊查询，其他参数忽略function search (opt) &#123; return new Promise((resolve) =&gt; &#123; let list = [ &#123; name: 'Admin Peter', phone: '313141414', status: 'status1', date: '2018-10-10' &#125;, &#123; name: 'Admin Marry', phone: '123931873', status: 'status2', date: '2018-11-11' &#125;, &#123; name: 'Admin Sue', phone: '342391873', status: 'status1', date: '2018-01-01' &#125;, &#123; name: 'Admin Join', phone: '143391873', status: 'status1', date: '2018-12-12' &#125; ] if (opt.name) &#123; list = list.filter(item =&gt; item.name.match(opt.name)) &#125; setTimeout(() =&gt; &#123; resolve(list) &#125;, 1000) &#125;)&#125;export default &#123; extends: ListPageAbstract, data () &#123; return &#123; title: '管理员列表' &#125; &#125;, methods: &#123; fetchOptions () &#123; ListPageAbstract.methods.fetchOptions.call(this) console.log('to do other thing') &#125;, async fetchData () &#123; let list = await search(this.filterForm) this.list = list &#125; &#125;&#125;&lt;/script&gt; 刷新页面就能呈现上述图一展示的样子和功能了。那么洋洋洒洒这么多代码做了些什么呢？ Title.vue 用于显示页面的标题（之后我们用它测试下继承于ListPageAbstract.vue的组件如何重写css的问题） ButtonClick.vue 展示操作按钮和执行操作事件 ListPageAbstract.vue 抽象的列表组件，这里是作为例子，具体方法定义的粗细程度根据具体情况调节 AdminListPage.vue 管理员列表的具体组件 AdminListPage通过extends继承了ListPageAbstract的模板、样式和其JS代码，通过部分的重写或完善，很容易的实现了一个页面，看上去很美好。那么新的问题来了，我们也发现ListPageAbstract定义筛选的内容是有限的，目前仅仅有name、phone、date和status，如果想扩展该怎么办呢？用过Vue的朋友或许此刻会想到Slot，接下来我们注释掉ListPageAbstract.vue里关于filter-slot的注释，并为AdminListPage.vue添加相关slot代码。 1234567// AdminListPage.vue add template &lt;template slot=\"filter-slot\"&gt; &lt;div slot=\"filter-slot\"&gt; other input filter &lt;/div&gt;&lt;/template&gt;&lt;script type=\"text/javascript\"&gt; 刷新页面，页面仅仅留下了“other input filter”一串字符串，并没有实现我们的需求；也有人提出其它修改意见 123456789101112131415// AdminListPage.vue &lt;template slot=\"filter-slot\"&gt; &lt;Page&gt; &lt;div slot=\"filter-slot\"&gt; other input filter &lt;/div&gt; &lt;/Page&gt;&lt;/template&gt;export default &#123; extends: ListPageAbstract, components: &#123; Page: ListPageAbstract, &#125; // ...&#125; 虽然页面UI层是预期显示了，但是如果对ListPageAbstract的mounted方法打断点会发现，它被执行了2次，因为被实例化了2次，并且页面上的元素事件使用的是ListPageAbstract里的，而不是我们在Admin里面重写的，显然方法并不可行。关于Vue模板级别的继承扩展问题在github上有很多的吐槽，但并没有列为未来的新feature #6811 既然我们讨论这个问题，自然也是可以解决的，在这我们不以filter查询条件的多少为例子，我们以更为简单的按钮为例，在列表里每一行的最后有一个“修改”按钮，而然我们在UserListPage里面，我们希望它变成一个“删除”按钮，并弹出确实删除的提示。新增ButtonPop.vue和UserListPage.vue 又是很多代码，没兴趣可跳过 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103// ButtonPop.vue&lt;template&gt; &lt;div&gt; &lt;el-button size=\"small\" plain type=\"primary\" @click.stop=\"dialogVisible = true\"&gt;&#123;&#123; label &#125;&#125;&lt;/el-button&gt; &lt;el-dialog title=\"提示\" :visible.sync=\"dialogVisible\" width=\"30%\"&gt; &lt;span&gt;确认删除数据吗？&lt;/span&gt; &lt;span slot=\"footer\" class=\"dialog-footer\"&gt; &lt;el-button @click=\"dialogVisible = false\"&gt;取 消&lt;/el-button&gt; &lt;el-button type=\"primary\" @click=\"deleteInfo\"&gt;确 定&lt;/el-button&gt; &lt;/span&gt; &lt;/el-dialog&gt; &lt;/div&gt;&lt;/template&gt;&lt;script type=\"text/javascript\"&gt;export default &#123; props: ['click', 'label', 'opt'], data () &#123; return &#123; dialogVisible: false &#125; &#125;, mounted () &#123; console.log('ButtonPop mounted') &#125;, methods: &#123; async deleteInfo () &#123; await this.click() this.dialogVisible = false &#125; &#125;&#125;&lt;/script&gt;// UserListPage.vue&lt;script type=\"text/javascript\"&gt;import ListPageAbstract from './ListPageAbstract.vue'import Button from './ButtonPop.vue'// 模拟ajax请求// 仅做了名字的模糊查询，其他参数忽略function search (opt) &#123; return new Promise((resolve) =&gt; &#123; let list = [ &#123; name: 'User Peter', phone: '313141414', status: 'status1', date: '2018-10-10' &#125;, &#123; name: 'User Marry', phone: '123931873', status: 'status2', date: '2018-11-11' &#125;, &#123; name: 'User Sue', phone: '342391873', status: 'status1', date: '2018-01-01' &#125;, &#123; name: 'User Join', phone: '143391873', status: 'status1', date: '2018-12-12' &#125; ] if (opt.name) &#123; list = list.filter(item =&gt; item.name.match(opt.name)) &#125; setTimeout(() =&gt; &#123; resolve(list) &#125;, 1000) &#125;)&#125;export default &#123; extends: ListPageAbstract, components: &#123; Button &#125;, data: function () &#123; return &#123;&#125; &#125;, mounted: function () &#123; this.title = '用户列表' &#125;, methods: &#123; createConfig () &#123; // 用户名、创建时间、手机号、状态 let config = ListPageAbstract.methods.createConfig.call(this) config.filter.conditions.splice(1, 0, 'phone') let table = config.table table.column.push(&#123; key: 'date', label: '时间' &#125;) table.action = &#123; headerLabel: '操作', label: '删除', click: this.deleteRow &#125; return config &#125;, async fetchData () &#123; let list = await search(this.filterForm) this.list = list &#125;, deleteRow (item) &#123; return new Promise((resolve, reject) =&gt; &#123; console.log(`delete date: $&#123;item.name&#125;`) setTimeout(() =&gt; &#123; this.list.splice(this.list.indexOf(item), 1) resolve() &#125;, 1000) &#125;) &#125; &#125;&#125;&lt;/script&gt;&lt;style type=\"text/css\"&gt;.title &#123; margin-bottom: 50px; color: blue;&#125;&lt;/style&gt; 然后在修改下App.vue里面的Page引用，从AdminListPage改为UserListPage 刷新页面，就和图二的样子一样了。整个代码并不复杂，核心就是 1components: &#123; Button &#125; 它将父类的Button（ButtonClick）替换成了User页面需要的ButtonPop，实现了扩展。其实Filter查询条件也可以，只要我们做好组件的抽取等就行。 阅读Vue的源码时候，在Vue组件实例化的过程中，会有很多对options的深层次merge，使得我们可以通过上诉方法实现对父组件的扩展。 另外，细心的朋友观察代码或页面也发现“用户列表”4个字的颜色从红色变成了蓝色，与下面列表的间距也增大了不少，在User页面的style标签里就能很容易修改父组件的css样式。 在Vue中，mixin、slot都是非常好用的工具，或许我们有时候也能改变思路，通过组件的替换构建出一个更为容易扩展的框架。","link":"/2018/11/17/vue-component-extends/"}],"tags":[{"name":"随想","slug":"随想","link":"/tags/随想/"},{"name":"Node.js","slug":"Node-js","link":"/tags/Node-js/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"性能监控","slug":"性能监控","link":"/tags/性能监控/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"架构","slug":"架构","link":"/tags/架构/"},{"name":"运维","slug":"运维","link":"/tags/运维/"}],"categories":[{"name":"work","slug":"work","link":"/categories/work/"},{"name":"架构","slug":"架构","link":"/categories/架构/"},{"name":"JavaScript","slug":"JavaScript","link":"/categories/JavaScript/"},{"name":"travel","slug":"travel","link":"/categories/travel/"}]}